---
title: "Perceptual Illusion"
subtitle: "Data Analysis"
author: "Fernando Millan Villalobos"
date: "February 2021"
output:
  html_document:
    code_folding: show
    echo: TRUE
    warning: FALSE
    message: FALSE
    highlight: pygments
    theme: paper
    df_print: kable
    toc: yes
    toc_depth: 4
    number_sections: yes
    toc_float: 
      collapsed: yes
      smooth_scroll: false
  pdf_document:
    toc: yes
  word_document:
    toc: yes
  allways_allow_html: yes
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../", output_file = "index") })
---

```{r, include=FALSE}
## By defult, show code for all chunks in the knitted document,
## as well as the output. To override for a particular chunk
## use echo = FALSE in its options.
knitr::opts_chunk$set(
   echo=TRUE, message=FALSE, warning=FALSE, fig.width=8, fig.height=5
)
```

```{r, echo=FALSE}
# CONFIG
user_name <- "fernandomillanvillalobos" # your Git username (only needed if
# you want to deploy to GH pages)
project_name <- "2020-perceptual-illusion-master" # adapt!
package_date <- "2021-01-01" # date of the CRAN snapshot that
# the checkpoint package uses
r_version <- "4.0.4" # R-Version to use
options(Ncpus = 4) # use 4 cores for parallelized installation of packages
if (r_version != paste0(version$major, ".", version$minor)) {
  stop("ERROR: specified R version does not match currently used.")
}
```

# Notes

This report was generated on `r Sys.time()`. R version: `r paste0(version$major, ".", version$minor)` on `r version$platform`. For this report, CRAN packages as of `r package_date` were used.

## R-Script & data

The pre-processing and analysis of the data was conducted in the [R project for statistical computing](https://www.r-project.org/). The RMarkdown script used to generate this document can be downloaded [under this link](http:fernandomillanvillalobs.github.io/2020-perceptual-illusion-master/). Through executing `main.Rmd`, the herein described process can be reproduced and this document can be generated. The data and information in the data sets used for this analysis are intended for use only by persons involved in the project, therefore are not available for the general public. The html on-line version of the analysis can be accessed through this [link](https://fernandomillanvillalobos.github.io/2020-perceptual-illusion-master/).

## GitHub

The code for the herein described process can also be freely downloaded from [https://github.com/fernandomillanvillalobs/2020-perceptual-illusion-master](https://github.com/fernandomillanvillalobos/2020-perceptual-illusion-master).

## Data description of output files

Output file: `df_pi.csv` (Example)

| ds_owner  | hemisphere | id | gender | age_group | 
|-----------|------------|----|--------|------------
| j         | northern   | 1  | f      | 30-39     |
| g         | northern   | 2  | m      | 20-29     |
| v         | southern   | 3  | m      | 20-29     |

# Set up

```{r, echo=FALSE}
detach_all_packages <- function() {
  basic_packages_blank <-  c("stats",
                             "graphics",
                             "grDevices",
                             "utils",
                             "datasets",
                             "methods",
                             "base")
  basic_packages <- paste("package:", basic_packages_blank, sep = "")

  package_list <- search()[
    ifelse(unlist(gregexpr("package:", search())) == 1, TRUE, FALSE)]

  package_list <- setdiff(package_list, basic_packages)

  if (length(package_list) > 0)  for (package in package_list) {
    detach(package, character.only = TRUE, unload = TRUE)
    print(paste("package ", package, " detached", sep = ""))
  }
}

detach_all_packages()

# this allows multiple persons to use the same RMarkdown
# without adjusting the working directory by themselves all the time
source("scripts/csf.R")
path_to_wd <- csf() # if this - for some reason - does not work,
# replace with a hardcoded path, like so: "~/projects/rddj-template/analysis/"
if (is.null(path_to_wd) | !dir.exists(path_to_wd)) {
  print("WARNING: No working directory specified for current user")
} else {
  setwd(path_to_wd)
}

# suppress scientific notation
options(scipen = 999)

# unload global rstudioapi and knitr again to avoid conflicts with checkpoint
# this is only necessary if executed within RStudio
# outside of RStudio, namely in the knit.sh script, this causes RMarkdown
# rendering to fail, thus should not be executed there
if (Sys.getenv("RSTUDIO") == "1") {
  detach_all_packages()
}
```

## Define packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# from https://mran.revolutionanalytics.com/web/packages/\
# checkpoint/vignettes/using-checkpoint-with-knitr.html
# if you don't need a package, remove it from here (commenting not sufficient)
# tidyverse: see https://blog.rstudio.org/2016/09/15/tidyverse-1-0-0/
cat("
library(rstudioapi)
library(tidyverse) # ggplot2, dplyr, tidyr, readr, purrr, tibble, magrittr, readxl
library(scales) # scales for ggplot2
library(jsonlite) # json
library(lintr) # code linting
library(sf) # spatial data handling
library(rmarkdown)
library(cowplot) # theme
library(extrafont) # fonts
library(waldo) # compare
library(psych) # some useful funs 
library(likert) # likert scales  
library(janitor)", # names  
file = "manifest.R")
```

## Install packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# if checkpoint is not yet installed, install it (for people using this
# system for the first time)
if (!require(checkpoint)) {
  if (!require(devtools)) {
    install.packages("devtools", repos = "http://cran.us.r-project.org")
    require(devtools)
  }
  devtools::install_github("RevolutionAnalytics/checkpoint",
                           ref = "v0.4.10", # could be adapted later,
                           # as of now (beginning of July 2017
                           # this is the current release on CRAN)
                           repos = "http://cran.us.r-project.org")
  require(checkpoint)
}
# nolint start
if (!dir.exists("~/.checkpoint")) {
  dir.create("~/.checkpoint")
}
# nolint end
# install packages for the specified CRAN snapshot date
checkpoint(snapshotDate = package_date,
           project = path_to_wd,
           verbose = T,
           scanForPackages = T,
           use.knitr = F,
           R.version = r_version)
rm(package_date)
```

## Load packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
source("manifest.R")
unlink("manifest.R")
sessionInfo()
```

## Load additional scripts

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# if you want to outsource logic to other script files, see README for 
# further information
# Load all visualizations functions as separate scripts
knitr::read_chunk("scripts/dviz.supp.R")
source("scripts/dviz.supp.R")
knitr::read_chunk("scripts/themes.R")
source("scripts/themes.R")
knitr::read_chunk("scripts/plot_grid.R")
source("scripts/plot_grid.R")
knitr::read_chunk("scripts/align_legend.R")
source("scripts/align_legend.R")
knitr::read_chunk("scripts/label_log10.R")
source("scripts/label_log10.R")
```

## Theme

```{r}
theme_set(theme_cowplot(font_size = 11))
```

# Data Wrangling

Importing datasets.

```{r importing}
# Read in data file
df.j <- read.table("input/ignore/j_ds.csv", sep = ",", header = TRUE, check.names = FALSE)
df.g <- read.table("input/ignore/g_ds.csv", sep = ",", header = TRUE, check.names = FALSE)
df.v <- read.table("input/ignore/v_ds.csv", sep = ",", header = TRUE, check.names = FALSE)
df.a <- read.table("input/ignore/a_ds.csv", sep = ",", header = TRUE, check.names = FALSE)

# Cleaning variables names
df.j <- janitor::clean_names(df.j, sep_in = NULL)
df.g <- janitor::clean_names(df.g, sep_in = NULL)
df.v <- janitor::clean_names(df.v, sep_in = NULL)
df.a <- janitor::clean_names(df.a, sep_in = NULL)
```

Cleaning Julien's ds variables.

```{r cleaning_j}
# Values to lowercase
df.j$srm <- unlist(lapply(df.j$srm, tolower))

# Regrouping hours_sleep bottom and top categories
df.j$hours_sleep[df.j$hours_sleep == "<3"] <- "less_than_3"
df.j$hours_sleep[df.j$hours_sleep == ">8"] <- "more_than_8"
df.j$hours_sleep[df.j$hours_sleep == "4"] <- "4-5"
df.j$hours_sleep[df.j$hours_sleep == "5"] <- "5-6"
df.j$hours_sleep[df.j$hours_sleep == "6"] <- "6-7"
df.j$hours_sleep[df.j$hours_sleep == "7"] <- "7-8"
df.j$hours_sleep[df.j$hours_sleep == "8"] <- "7-8"

# Filling empty values for circle_below and circle_above as NAs
df.j$circle_below[df.j$circle_below == ""] <- NA 
df.j$circle_above[df.j$circle_above == ""] <- NA

# Recoding srm, geovis_3d_exposure and satellite_exposure variables
df.j$srm[df.j$srm == "never"] <- 1
df.j$srm[df.j$srm == "rarely"] <- 2
df.j$srm[df.j$srm == "occassionally"] <- 3
df.j$srm[df.j$srm == "often"] <- 4
df.j$srm[df.j$srm == "daily"] <- 5
# srm
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "never"] <- 1
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "rarely"] <- 2
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "occassionally"] <- 3
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "often"] <- 4
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "daily"] <- 5
# geovis_3d_exposure
df.j$satellite_exposure[df.j$satellite_exposure == "never"] <- 1
df.j$satellite_exposure[df.j$satellite_exposure == "rarely"] <- 2
df.j$satellite_exposure[df.j$satellite_exposure == "occassionally"] <- 3
df.j$satellite_exposure[df.j$satellite_exposure == "often"] <- 4
df.j$satellite_exposure[df.j$satellite_exposure == "daily"] <- 5
# satellite_exposure

# Adding an expertise var based on srm
df.j$expertise[df.j$srm <= 2] <- "no_experience"
df.j$expertise[df.j$srm >= 2 & df.j$srm <= 4] <- "some_experience"

# Reordering variables
df.j <- df.j %>%
select(1:12, expertise, 13:20, mask, circle_below, circle_above,24:73)
```

Cleaning Gianna's ds variables.

```{r cleaning_g}
# Deleting useless column
df.g$haendigkeit <- NULL

# Renaming variables names
df.g <- df.g %>% 
  rename("age_group" = "alter",
         "education" = "ausbildung",
         "hours_sleep" = "schlaf",
         "color_blindness" = "farbenblindheit",
         "photo_exposure" = "fotos",
         "carto_gis_exposure" = "kartographie",
         "geovis_3d_exposure" = "drei_d_geovis",
         "satellite_exposure" = "satellitenbilder",
         "mask" = "maske")
```

```{r}
# Adding new variables
df.g <- transform(df.g,
                 art_light_r_w = NA, 
                 light_dir_r_s = NA,
                 photo_training = NA,
                 carto_gis_training = NA,
                 geovis_3d_training = NA,
                 satellite_training = NA,
                 circle_below = NA,
                 circle_above = NA,
                 shapes_01 = NA,
                 shapes_02 = NA,
                 shapes_03 = NA,
                 shapes_04 = NA,
                 shapes_05 = NA,
                 shapes_06 = NA,
                 shapes_07 = NA,
                 shapes_08 = NA,
                 shapes_09 = NA,
                 shapes_10 = NA,
                 srm = NA)

# Recoding education variable
df.g$education[df.g$education == "University: Bachelor degree or equivalent"] <- "bachelor"
df.g$education[df.g$education == "University of applied sciences"] <- "bachelor" # assumption! 
df.g$education[df.g$education == "University: Master degree or equivalent"] <- "master"
df.g$education[df.g$education == "University: Doctoral degree"] <- "doctoral"
df.g$education[df.g$education == "Apprenticeship high school"] <- "high_school"
df.g$education[df.g$education == "Academic high school"] <- "high_school"

# Regrouping age_group category
df.g$age_group[df.g$age_group == "18-29" & df.g$education == "bachelor" | df.g$education == "master"] <- "20-29"
df.g$age_group[df.g$age_group == "18-29" & df.g$education == "high_school"] <- "10-19"

# Regrouping hours_sleep bottom and top categories
df.g$hours_sleep[df.g$hours_sleep == "<3"] <- "less_than_3"
df.g$hours_sleep[df.g$hours_sleep == ">8"] <- "more_than_8"
df.g$hours_sleep[df.g$hours_sleep == "3"] <- "3-4"
df.g$hours_sleep[df.g$hours_sleep == "4"] <- "4-5"
df.g$hours_sleep[df.g$hours_sleep == "5"] <- "5-6"
df.g$hours_sleep[df.g$hours_sleep == "6"] <- "6-7"
df.g$hours_sleep[df.g$hours_sleep == "7"] <- "7-8"
df.g$hours_sleep[df.g$hours_sleep == "8"] <- "7-8"

# Values to lowercase
df.g[, 18:22] <- apply(df.g[, 18:22], 2, tolower)
df.g$color_blindness <- unlist(lapply(df.g$color_blindness, tolower))

# Recoding _exposure variables
df.g$photo_exposure[df.g$photo_exposure == "never"] <- 1
df.g$photo_exposure[df.g$photo_exposure == "rarely"] <- 2
df.g$photo_exposure[df.g$photo_exposure == "occasionally"] <- 3
df.g$photo_exposure[df.g$photo_exposure == "often"] <- 4
df.g$photo_exposure[df.g$photo_exposure == "daily"] <- 5
# photo_exposure
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "never"] <- 1
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "rarely"] <- 2
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "occasionally"] <- 3
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "often"] <- 4
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "daily"] <- 5
# carto_gis_exposure
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "never"] <- 1
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "rarely"] <- 2
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "occasionally"] <- 3
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "often"] <- 4
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "daily"] <- 5
# geovis_3d_exposure
df.g$satellite_exposure[df.g$satellite_exposure == "never"] <- 1
df.g$satellite_exposure[df.g$satellite_exposure == "rarely"] <- 2
df.g$satellite_exposure[df.g$satellite_exposure == "occasionally"] <- 3
df.g$satellite_exposure[df.g$satellite_exposure == "often"] <- 4
df.g$satellite_exposure[df.g$satellite_exposure == "daily"] <- 5
# satellite_exposure

# Converting new values to integer
df.g$photo_exposure <- as.integer(df.g$photo_exposure)
df.g$carto_gis_exposure <- as.integer(df.g$carto_gis_exposure)
df.g$geovis_3d_exposure <- as.integer(df.g$geovis_3d_exposure)
df.g$satellite_exposure <- as.integer(df.g$satellite_exposure)

# Adding an expertise var based on maps and/or satellite exposure
df.g$expertise[df.g$carto_gis_exposure <= 3 | df.g$geovis_3d_exposure <= 3 | df.g$satellite_exposure <= 3] <- "no_experience"
df.g$expertise[df.g$carto_gis_exposure > 3 | df.g$geovis_3d_exposure > 3 | df.g$satellite_exposure > 3] <- "some_experience"

# Reordering variables
df.g <- df.g[, names(df.j)]
```

Cleaning Victoria's ds variables.

```{r cleaning_v}
# Adding variables
df.v$hemisphere <- "southern"
df.v$srm <- "NA"

# Regrouping age_group category
df.v$age_group[df.v$age_group <= "29"] <- "20-29"

# Splitting character vector from hours_sleep
df.v$hours_sleep <- unlist(strsplit(df.v$hours_sleep, " hours"))

# Recoding education variable
df.v$education <- "bachelor"

# Values to lowercase
df.v$light_dir_r_s <- unlist(lapply(df.v$light_dir_r_s, tolower))

# Filling empty values for exposure variables
df.v$photo_exposure <- ifelse(df.v$photo_exposure == " ", NA, df.v$satellite_exposure)
df.v$carto_gis_exposure <- ifelse(df.v$carto_gis_exposure == " ", NA, df.v$carto_gis_exposure)
df.v$geovis_3d_exposure <- ifelse(df.v$geovis_3d_exposure == " ", NA, df.v$geovis_3d_exposure)
df.v$satellite_exposure <- ifelse(df.v$satellite_exposure == " ", NA, df.v$satellite_exposure)

# Recoding _exposure variables
df.v$photo_exposure[df.v$photo_exposure == "never"] <- 1
df.v$photo_exposure[df.v$photo_exposure == "daily"] <- 5
# photo_exposure
df.v$carto_gis_exposure[df.v$carto_gis_exposure == "never"] <- 1
df.v$carto_gis_exposure[df.v$carto_gis_exposure == "daily"] <- 5
# carto_gis_exposure
df.v$geovis_3d_exposure[df.v$geovis_3d_exposure == "never"] <- 1
df.v$geovis_3d_exposure[df.v$geovis_3d_exposure == "daily"] <- 5
# geovis_3d_exposure
df.v$satellite_exposure[df.v$satellite_exposure == "never"] <- 1
df.v$satellite_exposure[df.v$satellite_exposure == "daily"] <- 5
# satellite_exposure

# Converting new values to integer
df.v$photo_exposure <- as.integer(df.v$photo_exposure)
df.v$carto_gis_exposure <- as.integer(df.v$carto_gis_exposure)
df.v$geovis_3d_exposure <- as.integer(df.v$geovis_3d_exposure)
df.v$satellite_exposure <- as.integer(df.v$satellite_exposure)

# Calculating the expertise mean for every participant
df.v$expertise_mean <- rowSums(df.v[, 14:21], na.rm = TRUE) / 4

# Adding an expertise var based the expertise mean
df.v$expertise[df.v$expertise_mean < 4] <- "no_experience"
df.v$expertise[df.v$expertise_mean >= 4] <- "some_experience"

# Reordering variables
df.v <- df.v[, names(df.j)]
```

Cleaning Amy's ds variables.

```{r cleaning_a}
# Adding hemisphere variable
df.a$hemisphere <- "southern"
df.a$srm <- "NA"

# Regrouping age_group category
df.a$age_group[df.a$age_group <= "19"] <- "10-19"
df.a$age_group[df.a$age_group <= "29" & df.a$age_group >= 20] <- "20-29"
df.a$age_group[df.a$age_group <= "39" & df.a$age_group >= 30] <- "30-39"
df.a$age_group[df.a$age_group <= "49" & df.a$age_group >= 40] <- "40-49"
df.a$age_group[df.a$age_group <= "59" & df.a$age_group >= 50] <- "50-59"
df.a$age_group[df.a$age_group <= "69" & df.a$age_group >= 60] <- "60-69"

# Recoding education variable
df.a$education[df.a$education == "Currently registered at University/College for Bachelor degree or equivalent"] <- "bachelor"
df.a$education[df.a$education == "University/College: Bachelor degree or equivalent"] <- "bachelor"
df.a$education[df.a$education == "University/College: Honours, Masters, PhD degree or equivalent"] <- "master"
df.a$education[df.a$education == "High school diploma or equivalent ( e.g. NCS or matric )"] <- "high_school"

# Recoding hours_sleep
df.a$hours_sleep <- unlist(strsplit(df.a$hours_sleep, " hours")) # splitting characters
df.a$hours_sleep <- unlist(lapply(df.a$hours_sleep, tolower)) # values to lowercase  
df.a$hours_sleep[df.a$hours_sleep == "more than 8"] <- "more_than_8" # recoding

# Values to lowercase
df.a$art_light_r_w <- unlist(lapply(df.a$art_light_r_w, tolower))
df.a$light_dir_r_s <- unlist(lapply(df.a$light_dir_r_s, tolower))
df.a$color_blindness <- unlist(lapply(df.a$color_blindness, tolower))

# Filling empty values for exposure variables
df.a$photo_exposure <- ifelse(df.a$photo_exposure == " ", NA, df.a$satellite_exposure)
df.a$carto_gis_exposure <- ifelse(df.a$carto_gis_exposure == " ", NA, df.a$carto_gis_exposure)
df.a$geovis_3d_exposure <- ifelse(df.a$geovis_3d_exposure == " ", NA, df.a$geovis_3d_exposure)
df.a$satellite_exposure <- ifelse(df.a$satellite_exposure == " ", NA, df.a$satellite_exposure)

# Recoding _exposure variables
df.a$photo_exposure[df.a$photo_exposure == "never"] <- 1
df.a$photo_exposure[df.a$photo_exposure == "daily"] <- 5
# photo_exposure
df.a$carto_gis_exposure[df.a$carto_gis_exposure == "never"] <- 1
df.a$carto_gis_exposure[df.a$carto_gis_exposure == "daily"] <- 5
# carto_gis_exposure
df.a$geovis_3d_exposure[df.a$geovis_3d_exposure == "never"] <- 1
df.a$geovis_3d_exposure[df.a$geovis_3d_exposure == "daily"] <- 5
# geovis_3d_exposure
df.a$satellite_exposure[df.a$satellite_exposure == "never"] <- 1
df.a$satellite_exposure[df.a$satellite_exposure == "daily"] <- 5
# satellite_exposure

# Converting new values to integer
df.a$photo_exposure <- as.integer(df.a$photo_exposure)
df.a$carto_gis_exposure <- as.integer(df.a$carto_gis_exposure)
df.a$geovis_3d_exposure <- as.integer(df.a$geovis_3d_exposure)
df.a$satellite_exposure <- as.integer(df.a$satellite_exposure)

# Calculating the expertise mean for every participant
df.a$expertise_mean <- rowSums(df.a[, 14:21], na.rm = TRUE) / 4

# Adding an expertise var based on the expertise mean
df.a$expertise[df.a$expertise_mean < 4] <- "no_experience"
df.a$expertise[df.a$expertise_mean >= 4] <- "some_experience"

# Reordering variables
df.a <- df.a[, names(df.j)]
```

Creating all-in-one df for analysis and viz.

```{r wide_to_long}
# Creating a all-in-one wide df
df_wide <- rbind(df.j, df.g, df.v, df.a)

# Converting numeric vars to factor
cols <- c(35:74)
df_wide[, cols] <- lapply(df_wide[, cols] , factor)

# Reshaping from wide to long
df_long <- df_wide %>% pivot_longer(
  cols = q10_r000_0:q80_v135_337.5,
  names_to = c("landform", "land_dir", "light_dir"),
  names_pattern = "q?_(.)(.*)_(.*?..*)",
  values_to = "respond")
```

# Data Analysis

Setting accuracy and confidence.

```{r accuracy_confidence}
# Setting accuracy
ridge_t <- df_long$landform == "r" & (df_long$respond == "4" | df_long$respond == "5")
valley_t <- df_long$landform == "v" & (df_long$respond == "1" | df_long$respond == "2")
df_long$accuracy <- ifelse(ridge_t | valley_t , "yes", "no")

# Setting accuracy score
df_long$accuracy_score <- ifelse(df_long$respond == "1" | df_long$respond == "5", 1, 0)

# Setting confidence (out of 40)
df_long$confidence[df_long$respond == "1" | df_long$respond == "5"] <- "high_confidence"
df_long$confidence[df_long$respond == "2" | df_long$respond == "4"] <- "low_confidence"
df_long$confidence[df_long$respond == "3"] <- "ambiguous"

# Setting confidence score (out of 80)
df_long$confidence_score[df_long$respond == "1" | df_long$respond == "5"] <- 2
df_long$confidence_score[df_long$respond == "2" | df_long$respond == "4"] <- 1
df_long$confidence_score[df_long$respond == "3"] <- 0
```

## EDA

Exploring accuracy.

```{r eda_accuracy}
accu_hem <- df_long %>%
  group_by(hemisphere, accuracy) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(accuracy, pct)
accu_hem

p <- ggplot(accu_hem, aes(x = accuracy, y = pct, fill = hemisphere))
p + geom_bar(stat = "identity", position = "dodge2")

accu_hem_degrees <- df_long %>%
  group_by(hemisphere, accuracy, light_dir) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(accuracy, light_dir, pct)
accu_hem_degrees

p <- ggplot(accu_hem_degrees, aes(x = light_dir, y = pct, fill = hemisphere))
p + geom_bar(stat = "identity", position = "dodge2") +
  facet_grid(~ accuracy) +
  coord_flip()
```
Exploring confidence.

```{r eda_confidence}
confi_hem <- df_long %>%
  group_by(hemisphere, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(confidence, pct)
confi_hem

p <- ggplot(confi_hem, aes(x = confidence, y = pct, fill = hemisphere))
p + geom_bar(stat = "identity", position = "dodge2")

p <- ggplot(confi_hem, aes(x = hemisphere, y = pct, fill = confidence))
p + geom_bar(stat = "identity", color = "gray80") +
  coord_flip()
```
Confidence vs accuracy per respond.

```{r}
#  Setting accuracy per respond
accu_right_resp_degrees <- df_long %>%
  group_by(land_dir, light_dir, accuracy) %>% 
  summarize(N = n()) %>% 
  mutate(pct_accu_right = round(N / sum(N) * 100, 1)) %>% 
  filter(accuracy == "yes") %>% 
  select(-c(accuracy, N))

accu_wrong_resp_degrees <- df_long %>%
  group_by(land_dir, light_dir, accuracy) %>%
  summarize(N = n()) %>%
  mutate(pct_accu_wrong = round(N / sum(N) * 100, 1)) %>%
  filter(accuracy == "no") %>%
  select(-c(accuracy, N))

accu <- left_join(accu_right_resp_degrees, accu_wrong_resp_degrees, by = c("land_dir", "light_dir"))

#  Setting confidence per respond
confi_high_resp_degrees <- df_long %>%
  group_by(land_dir, light_dir, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct_high_confi = round(N / sum(N) * 100, 1)) %>%
  filter(confidence == "high_confidence") %>%
  select(-c(confidence, N))

confi_low_resp_degrees <- df_long %>%
  group_by(land_dir, light_dir, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct_low_confi = round(N / sum(N) * 100, 1)) %>%
  filter(confidence == "low_confidence") %>%
  select(-c(confidence, N))

confi_amb_resp_degrees <- df_long %>%
  group_by(land_dir, light_dir, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct_amb_confi = round(N / sum(N) * 100, 1)) %>%
  filter(confidence == "ambiguous") %>%
  select(-c(confidence, N))

confi1 <- left_join(confi_high_resp_degrees, confi_low_resp_degrees, by = c("land_dir", "light_dir"))
confi2 <- left_join(confi1, confi_amb_resp_degrees, by = c("land_dir", "light_dir"))
accu_confi <- left_join(accu, confi2, by = c("land_dir", "light_dir"))


p1 <- ggplot(accu_confi, aes(x = pct_accu_right, y = pct_high_confi, color = light_dir))
p1 + geom_point()

p2 <- ggplot(accu_confi, aes(x = pct_accu_right, y = pct_low_confi, color = light_dir))
p2 + geom_point()
```
# Linting

The code in this RMarkdown is linted with the [lintr package](https://github.com/jimhester/lintr), which is based on the [tidyverse style guide](http://style.tidyverse.org/).

```{r echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
# lintr::lint("main.Rmd", linters =
#               lintr::with_defaults(
#                 commented_code_linter = NULL,
#                 trailing_whitespace_linter = NULL
#                 )
#             )
# if you have additional scripts and want them to be linted too, add them here
# lintr::lint("scripts/my_script.R")
```
