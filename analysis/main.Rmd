---
title: "Perceptual Illusion"
subtitle: "Data Analysis"
author: "Fernando Millan Villalobos"
date: "February 2021"
output:
  html_document:
    code_folding: show
    echo: TRUE
    warning: FALSE
    message: FALSE
    highlight: pygments
    theme: paper
    df_print: kable
    toc: yes
    toc_depth: 5
    number_sections: yes
    toc_float: 
      collapsed: yes
      smooth_scroll: false
  pdf_document:
    toc: yes
  word_document:
    toc: yes
  allways_allow_html: yes
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../", output_file = "index") })
---

```{r, include=FALSE}
## By defult, show code for all chunks in the knitted document,
## as well as the output. To override for a particular chunk
## use echo = FALSE in its options.
knitr::opts_chunk$set(
   echo=TRUE, message=FALSE, warning=FALSE
)
```

```{r, echo=FALSE}
# CONFIG
user_name <- "fernandomillanvillalobos" # your Git username (only needed if
# you want to deploy to GH pages)
project_name <- "2020-perceptual-illusion-master" # adapt!
package_date <- "2021-01-01" # date of the CRAN snapshot that
# the checkpoint package uses
r_version <- "4.0.4" # R-Version to use
options(Ncpus = 4) # use 4 cores for parallelized installation of packages
if (r_version != paste0(version$major, ".", version$minor)) {
  stop("ERROR: specified R version does not match currently used.")
}
```

# Notes

This report was generated on `r Sys.time()`. R version: `r paste0(version$major, ".", version$minor)` on `r version$platform`. For this report, CRAN packages as of `r package_date` were used.

## R-Script & data

The pre-processing and analysis of the data was conducted in the [R project for statistical computing](https://www.r-project.org/). The RMarkdown script used to generate this document can be downloaded [under this link](http:fernandomillanvillalobs.github.io/2020-perceptual-illusion-master/). Through executing `main.Rmd`, the herein described process can be reproduced and this document can be generated. The data and information in the data sets used for this analysis are intended for use only by persons involved in the project, therefore are not available for the general public. The html on-line version of the analysis can be accessed through this [link](https://fernandomillanvillalobos.github.io/2020-perceptual-illusion-master/).

## GitHub

The code for the herein described process can also be freely downloaded from [https://github.com/fernandomillanvillalobs/2020-perceptual-illusion-master](https://github.com/fernandomillanvillalobos/2020-perceptual-illusion-master).

## Data description of output files

Output file: `df_pi.csv` (Example)

| ds_owner  | hemisphere | id | gender | age_group | 
|-----------|------------|----|--------|------------
| j         | northern   | 1  | f      | 30-39     |
| g         | northern   | 2  | m      | 20-29     |
| v         | southern   | 3  | m      | 20-29     |

# Set up

```{r, echo=FALSE}
detach_all_packages <- function() {
  basic_packages_blank <-  c("stats",
                             "graphics",
                             "grDevices",
                             "utils",
                             "datasets",
                             "methods",
                             "base")
  basic_packages <- paste("package:", basic_packages_blank, sep = "")

  package_list <- search()[
    ifelse(unlist(gregexpr("package:", search())) == 1, TRUE, FALSE)]

  package_list <- setdiff(package_list, basic_packages)

  if (length(package_list) > 0)  for (package in package_list) {
    detach(package, character.only = TRUE, unload = TRUE)
    print(paste("package ", package, " detached", sep = ""))
  }
}

detach_all_packages()

# this allows multiple persons to use the same RMarkdown
# without adjusting the working directory by themselves all the time
source("scripts/csf.R")
path_to_wd <- csf() # if this - for some reason - does not work,
# replace with a hardcoded path, like so: "~/projects/rddj-template/analysis/"
if (is.null(path_to_wd) | !dir.exists(path_to_wd)) {
  print("WARNING: No working directory specified for current user")
} else {
  setwd(path_to_wd)
}

# suppress scientific notation
options(scipen = 999)

# suppress summarise info
options(dplyr.summarise.inform = FALSE)

# unload global rstudioapi and knitr again to avoid conflicts with checkpoint
# this is only necessary if executed within RStudio
# outside of RStudio, namely in the knit.sh script, this causes RMarkdown
# rendering to fail, thus should not be executed there
if (Sys.getenv("RSTUDIO") == "1") {
  detach_all_packages()
}
```
## Define packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# from https://mran.revolutionanalytics.com/web/packages/\
# checkpoint/vignettes/using-checkpoint-with-knitr.html
# if you don't need a package, remove it from here (commenting not sufficient)
# tidyverse: see https://blog.rstudio.org/2016/09/15/tidyverse-1-0-0/
cat("
library(rstudioapi)
library(tidyverse, warn.conflicts = FALSE) # ggplot2, dplyr, tidyr, readr, purrr, tibble, magrittr, readxl
library(scales) # scales for ggplot2
library(jsonlite) # json
library(lintr) # code linting
library(sf) # spatial data handling
library(rmarkdown)
library(data.table)
library(cowplot) # theme
library(extrafont) # fonts
library(waldo) # compare
library(psych) # some useful funs 
library(ggrepel) # text labels 
library(treemap) # treemap plots 
library(skimr) # data quality 
library(janitor)", # names  
file = "manifest.R")
```

## Install packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# if checkpoint is not yet installed, install it (for people using this
# system for the first time)
if (!require(checkpoint)) {
  if (!require(devtools)) {
    install.packages("devtools", repos = "http://cran.us.r-project.org")
    require(devtools)
  }
  devtools::install_github("RevolutionAnalytics/checkpoint",
                           ref = "v0.4.10", # could be adapted later,
                           # as of now (beginning of July 2017
                           # this is the current release on CRAN)
                           repos = "http://cran.us.r-project.org")
  require(checkpoint)
}
# nolint start
if (!dir.exists("~/.checkpoint")) {
  dir.create("~/.checkpoint")
}
# nolint end
# install packages for the specified CRAN snapshot date
checkpoint(snapshotDate = package_date,
           project = path_to_wd,
           verbose = T,
           scanForPackages = T,
           use.knitr = F,
           R.version = r_version)
rm(package_date)
```

## Load packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
source("manifest.R")
unlink("manifest.R")
sessionInfo()
```
## Load additional scripts

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# if you want to outsource logic to other script files, see README for 
# further information
# Load all visualizations functions as separate scripts
knitr::read_chunk("scripts/dviz.supp.R")
source("scripts/dviz.supp.R")
knitr::read_chunk("scripts/themes.R")
source("scripts/themes.R")
knitr::read_chunk("scripts/plot_grid.R")
source("scripts/plot_grid.R")
knitr::read_chunk("scripts/align_legend.R")
source("scripts/align_legend.R")
knitr::read_chunk("scripts/label_log10.R")
source("scripts/label_log10.R")
knitr::read_chunk("scripts/outliers.R")
source("scripts/outliers.R")
```

## Theme

```{r}
theme_set(theme_cowplot(font_size = 11))
```

# Data Wrangling

Importing datasets.

```{r importing}
# Read in data file
df.j <- read.table("input/ignore/j_ds.csv", sep = ",", header = TRUE, check.names = FALSE)
df.g <- read.table("input/ignore/g_ds.csv", sep = ",", header = TRUE, check.names = FALSE)
df.v <- read.table("input/ignore/v_ds.csv", sep = ",", header = TRUE, check.names = FALSE)
df.a <- read.table("input/ignore/a_ds.csv", sep = ",", header = TRUE, check.names = FALSE)

# Cleaning variables names
df.j <- janitor::clean_names(df.j, sep_in = NULL)
df.g <- janitor::clean_names(df.g, sep_in = NULL)
df.v <- janitor::clean_names(df.v, sep_in = NULL)
df.a <- janitor::clean_names(df.a, sep_in = NULL)
```

Cleaning Julien's ds variables.

```{r cleaning_j}
# Values to lowercase
df.j$srm <- unlist(lapply(df.j$srm, tolower))

# Regrouping hours_sleep bottom and top categories
df.j$hours_sleep[df.j$hours_sleep == "<3"] <- "less_than_3"
df.j$hours_sleep[df.j$hours_sleep == ">8"] <- "more_than_8"
df.j$hours_sleep[df.j$hours_sleep == "4"] <- "4-5"
df.j$hours_sleep[df.j$hours_sleep == "5"] <- "5-6"
df.j$hours_sleep[df.j$hours_sleep == "6"] <- "6-7"
df.j$hours_sleep[df.j$hours_sleep == "7"] <- "7-8"
df.j$hours_sleep[df.j$hours_sleep == "8"] <- "7-8"

# Filling empty values for circle_below and circle_above as NAs
df.j$circle_below[df.j$circle_below == ""] <- NA 
df.j$circle_above[df.j$circle_above == ""] <- NA

# Recoding srm, geovis_3d_exposure and satellite_exposure variables
df.j$srm[df.j$srm == "never"] <- 1
df.j$srm[df.j$srm == "rarely"] <- 2
df.j$srm[df.j$srm == "occassionally"] <- 3
df.j$srm[df.j$srm == "often"] <- 4
df.j$srm[df.j$srm == "daily"] <- 5
# srm
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "never"] <- 1
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "rarely"] <- 2
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "occassionally"] <- 3
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "often"] <- 4
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "daily"] <- 5
# geovis_3d_exposure
df.j$satellite_exposure[df.j$satellite_exposure == "never"] <- 1
df.j$satellite_exposure[df.j$satellite_exposure == "rarely"] <- 2
df.j$satellite_exposure[df.j$satellite_exposure == "occassionally"] <- 3
df.j$satellite_exposure[df.j$satellite_exposure == "often"] <- 4
df.j$satellite_exposure[df.j$satellite_exposure == "daily"] <- 5
# satellite_exposure

# Adding an expertise var based on srm
df.j$expertise[df.j$srm <= 2] <- "no_experience"
df.j$expertise[df.j$srm >= 2 & df.j$srm <= 4] <- "some_experience"

# Reordering variables
df.j <- df.j %>%
select(1:12, expertise, 13:20, mask, circle_below, circle_above,24:73)
```

Cleaning Gianna's ds variables.

```{r cleaning_g}
# Deleting useless column
df.g$haendigkeit <- NULL

# Renaming variables names
df.g <- df.g %>% 
  rename("age_group" = "alter",
         "education" = "ausbildung",
         "hours_sleep" = "schlaf",
         "color_blindness" = "farbenblindheit",
         "photo_exposure" = "fotos",
         "carto_gis_exposure" = "kartographie",
         "geovis_3d_exposure" = "drei_d_geovis",
         "satellite_exposure" = "satellitenbilder",
         "mask" = "maske")
```

```{r}
# Adding new variables
df.g <- transform(df.g,
                 art_light_r_w = NA, 
                 light_dir_r_s = NA,
                 photo_training = NA,
                 carto_gis_training = NA,
                 geovis_3d_training = NA,
                 satellite_training = NA,
                 expertise = NA,
                 circle_below = NA,
                 circle_above = NA,
                 shapes_01 = NA,
                 shapes_02 = NA,
                 shapes_03 = NA,
                 shapes_04 = NA,
                 shapes_05 = NA,
                 shapes_06 = NA,
                 shapes_07 = NA,
                 shapes_08 = NA,
                 shapes_09 = NA,
                 shapes_10 = NA,
                 srm = NA)

# Recoding education variable
df.g$education[df.g$education == "University: Bachelor degree or equivalent"] <- "bachelor"
df.g$education[df.g$education == "University of applied sciences"] <- "bachelor" # assumption! 
df.g$education[df.g$education == "University: Master degree or equivalent"] <- "master"
df.g$education[df.g$education == "University: Doctoral degree"] <- "doctoral"
df.g$education[df.g$education == "Apprenticeship high school"] <- "high_school"
df.g$education[df.g$education == "Academic high school"] <- "high_school"

# Regrouping age_group category
df.g$age_group[df.g$age_group == "18-29" & df.g$education == "bachelor" | df.g$education == "master"] <- "20-29"
df.g$age_group[df.g$age_group == "18-29" & df.g$education == "high_school"] <- "10-19"

# Regrouping hours_sleep bottom and top categories
df.g$hours_sleep[df.g$hours_sleep == "<3"] <- "less_than_3"
df.g$hours_sleep[df.g$hours_sleep == ">8"] <- "more_than_8"
df.g$hours_sleep[df.g$hours_sleep == "3"] <- "3-4"
df.g$hours_sleep[df.g$hours_sleep == "4"] <- "4-5"
df.g$hours_sleep[df.g$hours_sleep == "5"] <- "5-6"
df.g$hours_sleep[df.g$hours_sleep == "6"] <- "6-7"
df.g$hours_sleep[df.g$hours_sleep == "7"] <- "7-8"
df.g$hours_sleep[df.g$hours_sleep == "8"] <- "7-8"

# Values to lowercase
df.g[, 10:14] <- apply(df.g[, 10:14], 2, tolower)
df.g$color_blindness <- unlist(lapply(df.g$color_blindness, tolower))

# Recoding _exposure variables
df.g$photo_exposure[df.g$photo_exposure == "never"] <- 1
df.g$photo_exposure[df.g$photo_exposure == "rarely"] <- 2
df.g$photo_exposure[df.g$photo_exposure == "occasionally"] <- 3
df.g$photo_exposure[df.g$photo_exposure == "often"] <- 4
df.g$photo_exposure[df.g$photo_exposure == "daily"] <- 5
# photo_exposure
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "never"] <- 1
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "rarely"] <- 2
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "occasionally"] <- 3
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "often"] <- 4
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "daily"] <- 5
# carto_gis_exposure
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "never"] <- 1
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "rarely"] <- 2
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "occasionally"] <- 3
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "often"] <- 4
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "daily"] <- 5
# geovis_3d_exposure
df.g$satellite_exposure[df.g$satellite_exposure == "never"] <- 1
df.g$satellite_exposure[df.g$satellite_exposure == "rarely"] <- 2
df.g$satellite_exposure[df.g$satellite_exposure == "occasionally"] <- 3
df.g$satellite_exposure[df.g$satellite_exposure == "often"] <- 4
df.g$satellite_exposure[df.g$satellite_exposure == "daily"] <- 5
# satellite_exposure

# Converting new values to integer
df.g$photo_exposure <- as.integer(df.g$photo_exposure)
df.g$carto_gis_exposure <- as.integer(df.g$carto_gis_exposure)
df.g$geovis_3d_exposure <- as.integer(df.g$geovis_3d_exposure)
df.g$satellite_exposure <- as.integer(df.g$satellite_exposure)

# Adding an expertise var based on maps and/or satellite exposure
df.g$expertise[df.g$carto_gis_exposure <= 3 | df.g$geovis_3d_exposure <= 3 | df.g$satellite_exposure <= 3] <- "no_experience"
df.g$expertise[df.g$carto_gis_exposure > 3 | df.g$geovis_3d_exposure > 3 | df.g$satellite_exposure > 3] <- "some_experience"

# Reordering variables
df.g <- df.g[, names(df.j)]
```

Cleaning Victoria's ds variables.

```{r cleaning_v}
# Adding variables
df.v$hemisphere <- "southern"
df.v$srm <- "NA"
df.v$expertise <- "NA"

# Regrouping age_group category
df.v$age_group[df.v$age_group <= "29"] <- "20-29"

# Splitting character vector from hours_sleep
df.v$hours_sleep <- unlist(strsplit(df.v$hours_sleep, " hours"))

# Recoding education variable
df.v$education <- "bachelor"

# Values to lowercase
df.v$light_dir_r_s <- unlist(lapply(df.v$light_dir_r_s, tolower))

# Filling empty values for exposure variables
df.v$photo_exposure <- ifelse(df.v$photo_exposure == " ", NA, df.v$satellite_exposure)
df.v$carto_gis_exposure <- ifelse(df.v$carto_gis_exposure == " ", NA, df.v$carto_gis_exposure)
df.v$geovis_3d_exposure <- ifelse(df.v$geovis_3d_exposure == " ", NA, df.v$geovis_3d_exposure)
df.v$satellite_exposure <- ifelse(df.v$satellite_exposure == " ", NA, df.v$satellite_exposure)

# Recoding _exposure variables
df.v$photo_exposure[df.v$photo_exposure == "never"] <- 1
df.v$photo_exposure[df.v$photo_exposure == "daily"] <- 5
# photo_exposure
df.v$carto_gis_exposure[df.v$carto_gis_exposure == "never"] <- 1
df.v$carto_gis_exposure[df.v$carto_gis_exposure == "daily"] <- 5
# carto_gis_exposure
df.v$geovis_3d_exposure[df.v$geovis_3d_exposure == "never"] <- 1
df.v$geovis_3d_exposure[df.v$geovis_3d_exposure == "daily"] <- 5
# geovis_3d_exposure
df.v$satellite_exposure[df.v$satellite_exposure == "never"] <- 1
df.v$satellite_exposure[df.v$satellite_exposure == "daily"] <- 5
# satellite_exposure

# Converting new values to integer
df.v$photo_exposure <- as.integer(df.v$photo_exposure)
df.v$carto_gis_exposure <- as.integer(df.v$carto_gis_exposure)
df.v$geovis_3d_exposure <- as.integer(df.v$geovis_3d_exposure)
df.v$satellite_exposure <- as.integer(df.v$satellite_exposure)

# Calculating the expertise mean for every participant
df.v$expertise_mean <- rowSums(df.v[, 14:21], na.rm = TRUE) / 4

# Adding an expertise var based the expertise mean
df.v$expertise[df.v$expertise_mean < 4] <- "no_experience"
df.v$expertise[df.v$expertise_mean >= 4] <- "some_experience"

# Reordering variables
df.v <- df.v[, names(df.j)]
```

Cleaning Amy's ds variables.

```{r cleaning_a}
# Adding hemisphere variable
df.a$hemisphere <- "southern"
df.a$srm <- "NA"
df.a$expertise <- "NA"

# Regrouping age_group category
df.a$age_group[df.a$age_group <= "19"] <- "10-19"
df.a$age_group[df.a$age_group <= "29" & df.a$age_group >= 20] <- "20-29"
df.a$age_group[df.a$age_group <= "39" & df.a$age_group >= 30] <- "30-39"
df.a$age_group[df.a$age_group <= "49" & df.a$age_group >= 40] <- "40-49"
df.a$age_group[df.a$age_group <= "59" & df.a$age_group >= 50] <- "50-59"
df.a$age_group[df.a$age_group <= "69" & df.a$age_group >= 60] <- "60-69"

# Recoding education variable
df.a$education[df.a$education == "Currently registered at University/College for Bachelor degree or equivalent"] <- "bachelor"
df.a$education[df.a$education == "University/College: Bachelor degree or equivalent"] <- "bachelor"
df.a$education[df.a$education == "University/College: Honours, Masters, PhD degree or equivalent"] <- "master"
df.a$education[df.a$education == "High school diploma or equivalent ( e.g. NCS or matric )"] <- "high_school"

# Recoding hours_sleep
df.a$hours_sleep <- unlist(strsplit(df.a$hours_sleep, " hours")) # splitting characters
df.a$hours_sleep <- unlist(lapply(df.a$hours_sleep, tolower)) # values to lowercase  
df.a$hours_sleep[df.a$hours_sleep == "more than 8"] <- "more_than_8" # recoding

# Values to lowercase
df.a$art_light_r_w <- unlist(lapply(df.a$art_light_r_w, tolower))
df.a$light_dir_r_s <- unlist(lapply(df.a$light_dir_r_s, tolower))
df.a$color_blindness <- unlist(lapply(df.a$color_blindness, tolower))

# Filling empty values for exposure variables
df.a$photo_exposure <- ifelse(df.a$photo_exposure == " ", NA, df.a$satellite_exposure)
df.a$carto_gis_exposure <- ifelse(df.a$carto_gis_exposure == " ", NA, df.a$carto_gis_exposure)
df.a$geovis_3d_exposure <- ifelse(df.a$geovis_3d_exposure == " ", NA, df.a$geovis_3d_exposure)
df.a$satellite_exposure <- ifelse(df.a$satellite_exposure == " ", NA, df.a$satellite_exposure)

# Recoding _exposure variables
df.a$photo_exposure[df.a$photo_exposure == "never"] <- 1
df.a$photo_exposure[df.a$photo_exposure == "daily"] <- 5
# photo_exposure
df.a$carto_gis_exposure[df.a$carto_gis_exposure == "never"] <- 1
df.a$carto_gis_exposure[df.a$carto_gis_exposure == "daily"] <- 5
# carto_gis_exposure
df.a$geovis_3d_exposure[df.a$geovis_3d_exposure == "never"] <- 1
df.a$geovis_3d_exposure[df.a$geovis_3d_exposure == "daily"] <- 5
# geovis_3d_exposure
df.a$satellite_exposure[df.a$satellite_exposure == "never"] <- 1
df.a$satellite_exposure[df.a$satellite_exposure == "daily"] <- 5
# satellite_exposure

# Converting new values to integer
df.a$photo_exposure <- as.integer(df.a$photo_exposure)
df.a$carto_gis_exposure <- as.integer(df.a$carto_gis_exposure)
df.a$geovis_3d_exposure <- as.integer(df.a$geovis_3d_exposure)
df.a$satellite_exposure <- as.integer(df.a$satellite_exposure)

# Calculating the expertise mean for every participant
df.a$expertise_mean <- rowSums(df.a[, 14:21], na.rm = TRUE) / 4

# Adding an expertise var based on the expertise mean
df.a$expertise[df.a$expertise_mean < 4] <- "no_experience"
df.a$expertise[df.a$expertise_mean >= 4] <- "some_experience"

# Reordering variables
df.a <- df.a[, names(df.j)]
```

Creating all-in-one df for analysis and viz.

```{r wide_to_long}
# Creating a all-in-one wide df
df_wide <- rbind(df.j, df.g, df.v, df.a)

# Converting numeric vars to factor
cols <- c(35:74)
df_wide[, cols] <- lapply(df_wide[, cols] , factor)

# Reshaping from wide to long
df_long <- df_wide %>% pivot_longer(
  cols = q10_r000_0:q80_v135_337.5,
  names_to = c("landform", "land_dir", "light_dir"),
  names_pattern = "q?_(.)(.*)_(.*?..*)",
  values_to = "respond")
```

# Data Analysis

Setting accuracy and confidence.

```{r accuracy_confidence}
# Setting accuracy
ridge_t <- df_long$landform == "r" & (df_long$respond == "4" | df_long$respond == "5")
ridge_f <- df_long$landform == "r" & (df_long$respond == "1" | df_long$respond == "2")
valley_t <- df_long$landform == "v" & (df_long$respond == "1" | df_long$respond == "2")
valley_f <- df_long$landform == "v" & (df_long$respond == "4" | df_long$respond == "5")
df_long$accuracy <- ifelse(ridge_t | valley_t , "yes", "no")

# Setting confidence
df_long$confidence <- "NA"
df_long$confidence[df_long$respond == "1" | df_long$respond == "5"] <- "high_confidence"
df_long$confidence[df_long$respond == "2" | df_long$respond == "4"] <- "low_confidence"
df_long$confidence[df_long$respond == "3"] <- "ambiguous"
```

## EDA

### Exploring accuracy

```{r eda_accuracy_setting}
# Calculating accuracy per participant
accu_part <- df_long %>% 
  filter(accuracy == "yes") %>%
  group_by(ds_owner, id) %>% 
  mutate(accu_count = n(),
         accu_pct = round(accu_count / 40 * 100, 1)) %>% 
  ungroup() %>%
  select(ds_owner, id, accu_count, accu_pct)

# Looking for outliers
p <- ggplot(accu_part, aes(x = ds_owner, y = accu_pct))
p + geom_boxplot(fill = "#85CFE6") +
  scale_y_continuous(labels = scales::label_percent(scale = 1)) +
  labs(x = "Data Set Owner", y = "Accuracy (%)",
       title = "Spotting Outliers for Accuracy")

outlierSummary(accu_part$accu_pct)

# Assessing outliers
accu_part_outliers <- accu_part %>% 
  mutate(zscore = (accu_pct - mean(accu_pct)) / sd(accu_pct),
         outlier = ifelse(zscore > 2.58 | zscore < -2.58, "yes", "no")) %>% 
  filter(outlier == "yes") %>% 
  group_by(ds_owner, id) %>% 
  summarise()

# Getting rid of outliers
outliers <- c(16, 11, 12, 2, 6, 32, 60, 73, 77, 80)
df_long_clean <- df_long %>% 
  filter(!(!ds_owner == "j" & id == outliers))
```

Notes about outliers: 
- from Victoria's ds participant number 72 was excluded when calculating accuracy because he answered all questions wrong (meaning: accuracy = "no").
- Also from Victoria's ds, participant number 68 got a low rating (52.5) but according to our outlier definition (> 2.58 | < -2.58), it cannot be considered an outlier.

```{r, eda_accuracy_exploring}
# Calculating accuracy per respond
accu_resp_j <- df_long_clean %>% 
  filter(accuracy == "yes",
         ds_owner == "j") %>% 
  group_by(ds_owner, landform, land_dir, light_dir) %>%
  summarise(accu_count = n()) %>% 
  mutate(accu_pct = accu_count / 27 * 100)

accu_resp_g <- df_long_clean %>% 
  filter(accuracy == "yes",
         ds_owner == "g") %>% 
  group_by(ds_owner, landform, land_dir, light_dir) %>%
  summarise(accu_count = n()) %>% 
  mutate(accu_pct = accu_count / 35 * 100)

accu_resp_v <- df_long_clean %>% 
  filter(accuracy == "yes",
         ds_owner == "v") %>% 
  group_by(ds_owner, landform, land_dir, light_dir) %>%
  summarise(accu_count = n()) %>% 
  mutate(accu_pct = accu_count / 87 * 100)

accu_resp_a <- df_long_clean %>% 
  filter(accuracy == "yes",
         ds_owner == "a") %>% 
  group_by(ds_owner, landform, land_dir, light_dir) %>%
  summarise(accu_count = n()) %>% 
  mutate(accu_pct = accu_count / 41 * 100)

accu_resp <- rbind(accu_resp_j, accu_resp_g, accu_resp_v, accu_resp_a)

# Calculating accuracy mean per light direction
accu_resp_north <- accu_resp %>% 
  group_by(ds_owner, light_dir) %>% 
  summarise(mean = mean(accu_pct))

accu_resp_north <- within(accu_resp_north, ds_owner <- factor(ds_owner, levels = c("j", "g", "v", "a")))
accu_resp_north <- within(accu_resp_north, light_dir <- factor(light_dir, levels = c(0, 337.5, 315, 292.5, 270)))

p <- ggplot(accu_resp_north, aes(x = light_dir, y = mean, fill = light_dir, label = mean))
p + geom_bar(stat = "identity", alpha = .9) +
    scale_fill_brewer(type = "qual", palette = "Dark2") +
    scale_y_continuous(labels = scales::label_percent(scale = 1),
                       expand = expansion(mult = c(0, 0.05))) +
    labs(x = NULL, y = "Mean",
         fill = "Light Direction",
         title = "Mean accuracy per data set owner (NW)") +
    geom_text(aes(y = mean, label = round(mean, digits = 1)), position = position_dodge2(width = 1), vjust = 2, size = rel(3), family = dviz_font_family) +
    facet_wrap(~ ds_owner) +
    theme_dviz_hgrid() +
    theme(
      legend.position = "NULL",
      strip.background = element_blank(),
      axis.line.x.bottom = element_line(size = .3, color = "black"),
      axis.ticks.x = element_blank())

# Calculating accuracy mean per light direction and hemisphere
accu_resp_n_hem <- accu_resp_north %>%
  filter(ds_owner == "j" | ds_owner == "g") %>%
  group_by(light_dir) %>%
  summarise(north = mean(mean))

accu_resp_s_hem <- accu_resp_north %>%
  filter(ds_owner == "v" | ds_owner == "a") %>%
  group_by(light_dir) %>%
  summarise(south = mean(mean))

accu_resp_hem <- left_join(accu_resp_n_hem, accu_resp_s_hem, by = "light_dir")

accu_resp_hem_long <- accu_resp_hem %>% pivot_longer(-light_dir, names_to = "hemisphere", values_to = "mean")
 
p <- ggplot(accu_resp_hem_long, aes(x = light_dir, y = mean, fill = hemisphere))
p + geom_bar(stat = "identity", position = "dodge2", alpha = .9) +
    scale_fill_brewer(type = "qual", palette = "Dark2") +
    scale_y_continuous(labels = scales::label_percent(scale = 1),
                       expand = expansion(mult = c(0, 0.05)),
                       limits = c(0, 100)) +
    geom_text(aes(y = mean, label = round(mean, digits = 1)), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3), family = dviz_font_family) +
    labs(x = NULL, y = "Mean",
         fill = "Hemisphere",
         title = "Mean accuracy per hemisphere (NW)") +
    theme_dviz_hgrid() +
    theme(legend.position = "top",
    axis.line.x.bottom = element_line(size = .5, color = "black"),
    axis.ticks.x = element_blank())

# Calculating accuracy per participant and handedness
accu_hand_l <- df_long_clean %>% 
  filter(accuracy == "yes",
         handedness == "l") %>%
  group_by(ds_owner, id, handedness) %>% 
  mutate(accu_count = n(),
         accu_pct = round(accu_count / 40 * 100, 1)) %>% 
  ungroup() %>% 
  select(ds_owner, id, handedness, accu_count, accu_pct)

accu_hand_r <- df_long_clean %>% 
  filter(accuracy == "yes",
         handedness == "r") %>%
  group_by(ds_owner, id, handedness) %>% 
  mutate(accu_count = n(),
         accu_pct = round(accu_count / 40 * 100, 1)) %>% 
  ungroup() %>% 
  select(ds_owner, id, handedness, accu_count, accu_pct)

accu_hand_b <- df_long_clean %>% 
  filter(accuracy == "yes",
         handedness == "b") %>%
  group_by(ds_owner, id, handedness) %>% 
  mutate(accu_count = n(),
         accu_pct = round(accu_count / 40 * 100, 1)) %>% 
  ungroup() %>% 
  select(ds_owner, id, handedness, accu_count, accu_pct)

# Calculating accuracy per handedness and respond
accu_resp_hand_l <- df_long_clean %>%
  filter(accuracy == "yes",
         handedness == "l" | handedness == "b") %>%
  group_by(landform, land_dir, light_dir) %>%
  summarise(accu_count = n()) %>%
  mutate(accu_left = accu_count / 34 * 100) %>%
  ungroup() %>%
  select(landform,land_dir, light_dir, accu_left)

accu_resp_hand_r <- df_long_clean %>%
  filter(accuracy == "yes",
         handedness == "r") %>%
  group_by(landform, land_dir, light_dir) %>%
  summarise(accu_count = n()) %>%
  mutate(accu_right = accu_count / 156 * 100) %>%
  ungroup() %>%
  select(landform, land_dir, light_dir, accu_right)

accu_resp_hand <-  accu_resp_hand_l %>% left_join(accu_resp_hand_r)

# Calculating accuracy per handedness and respond (northern light direction)
accu_hand_l_north<- accu_resp_hand %>%
  group_by(light_dir) %>%
  summarise(left = mean(accu_left))

accu_hand_r_north<- accu_resp_hand %>%
  group_by(light_dir) %>%
  summarise(right = mean(accu_right))

accu_hand_north <- accu_hand_l_north %>% left_join(accu_hand_r_north)

accu_hand_north_long <- accu_hand_north %>% pivot_longer(-light_dir, names_to = "handedness", values_to = "mean")

accu_hand_north_long <- within(accu_hand_north_long, light_dir <- factor(light_dir, levels = c(0, 337.5, 315, 292.5, 270)))

p <- ggplot(accu_hand_north_long, aes(x = light_dir, y = mean, fill = handedness))
p + geom_bar(stat = "identity", position = "dodge2", alpha =.9) +
    scale_fill_brewer(type = "qual", palette = "Dark2") +
    scale_y_continuous(labels = scales::label_percent(scale = 1),
                       expand = expansion(mult = c(0, 0.05)),
                       limits = c(0, 100)) +
    geom_text(aes(y = mean, label = round(mean, digits = 1)), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3), family = dviz_font_family) +
    labs(x = NULL, y = "Mean",
         fill = "Handedness",
         title = "Mean accuracy per handedness (NW)") +
    theme_dviz_hgrid() +
    theme(legend.position = "top",
    axis.line.x.bottom = element_line(size = .5, color = "black"),
    axis.ticks.x = element_blank())

# Calculating accuracy per gender and respond
accu_gender_m <- df_long_clean %>% 
  filter(accuracy == "yes",
         gender == "m") %>% 
  group_by(landform, land_dir, light_dir) %>% 
  summarise(accu_count = n()) %>% 
  mutate(male_pct = accu_count / 104 * 100) %>% 
  select(landform, land_dir, light_dir, male_pct)

accu_gender_f <- df_long %>% 
  filter(accuracy == "yes",
         gender == "f") %>% 
  group_by(landform, land_dir, light_dir) %>% 
  summarise(accu_count = n()) %>% 
  mutate(female_pct = accu_count / 86 * 100) %>% 
  select(landform, land_dir, light_dir, female_pct)

accu_gender <- accu_gender_m %>% left_join(accu_gender_f)

# Calculating accuracy per gender and respond (northern light direction)
accu_gender_north_m <- accu_gender %>% 
  group_by(light_dir) %>% 
  summarise(male = mean(male_pct))

accu_gender_north_f <- accu_gender %>% 
  group_by(light_dir) %>% 
  summarise(female = mean(female_pct))

accu_gender_north <- accu_gender_north_m %>% left_join(accu_gender_north_f)

accu_gender_north_long <- accu_gender_north %>% pivot_longer(-light_dir, names_to = "gender", values_to = "mean")

accu_gender_north_long <- within(accu_gender_north_long, light_dir <- factor(light_dir, levels = c(0, 337.5, 315, 292.5, 270)))

p <- ggplot(accu_gender_north_long, aes(x = light_dir, y = mean, fill = gender))
p + geom_bar(stat = "identity", position = "dodge2", alpha = .9) +
    scale_fill_brewer(type = "qual", palette = "Dark2") +
    scale_y_continuous(labels = scales::label_percent(scale = 1),
                       expand = expansion(mult = c(0, 0.05)),
                       limits = c(0, 100)) +
    geom_text(aes(y = mean, label = round(mean, digits = 1)), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3), family = dviz_font_family) +
    labs(x = NULL, y = "Mean",
         fill = "Gender",
         title = "Mean accuracy per gender (NW)") +
    theme_dviz_hgrid() +
    theme(legend.position = "top",
    axis.line.x.bottom = element_line(size = .5, color = "black"),
    axis.ticks.x = element_blank())

# Calculating accuracy per expertise and respond
accu_exp_some <- df_long_clean %>% 
  filter(accuracy == "yes",
         expertise == "some_experience") %>% 
  group_by(landform, land_dir, light_dir) %>% 
  summarise(accu_count = n()) %>% 
  mutate(some_pct = accu_count / 40 * 100) %>% 
  select(landform, land_dir, light_dir, some_pct)

accu_exp_no <- df_long_clean %>% 
  filter(accuracy == "yes",
         expertise == "no_experience") %>% 
  group_by(landform, land_dir, light_dir) %>% 
  summarise(accu_count = n()) %>% 
  mutate(no_pct = accu_count / 150 * 100) %>% 
  select(landform, land_dir, light_dir, no_pct)

accu_exp <- accu_exp_some %>% left_join(accu_exp_no)

# Calculating accuracy per expertise and respond (northern light direction)
accu_exp_some_north <- accu_exp %>%
  group_by(light_dir) %>%
  summarise(some = mean(some_pct))

accu_exp_no_north <- accu_exp %>%
  group_by(light_dir) %>%
  summarise(no = mean(no_pct))

accu_exp_north <- accu_exp_some_north %>% left_join(accu_exp_no_north)

accu_exp_north_long <- accu_exp_north %>% pivot_longer(-light_dir, names_to = "expertise", values_to = "mean")

accu_exp_north_long <- within(accu_exp_north_long, light_dir <- factor(light_dir, levels = c(0, 337.5, 315, 292.5, 270)))

p <- ggplot(accu_exp_north_long, aes(x = light_dir, y = mean, fill = expertise))
p + geom_bar(stat = "identity", position = "dodge2", alpha = .9) +
    scale_fill_brewer(type = "qual", palette = "Dark2") +
    scale_y_continuous(labels = scales::label_percent(scale = 1),
                       expand = expansion(mult = c(0, 0.05)),
                       limits = c(0, 100)) +
    geom_text(aes(y = mean, label = round(mean, digits = 1)), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3), family = dviz_font_family) +
    labs(x = NULL, y = "Mean",
         fill = "Expertise",
         title = "Mean accuracy per expertise (NW)") +
    theme_dviz_hgrid() +
    theme(legend.position = "top",
          axis.line.x.bottom = element_line(size = .5, color = "black"),
          axis.ticks.x = element_blank())

# Expertise vs handedness
accu_exp_hand <-  left_join(accu_hand_north_long %>% 
                              rename(mean_hand = mean), 
                            accu_exp_north_long %>% 
                              rename(mean_exp = mean),
                            by = "light_dir") %>% 
  mutate(mean = (mean_hand + mean_exp) / 2) %>% 
  select(-c(mean_hand, mean_exp))

accu_exp_hand <- within(accu_exp_hand, light_dir <- factor(light_dir, levels = c(0, 337.5, 315, 292.5, 270)))
accu_exp_hand <- within(accu_exp_hand, expertise <- factor(expertise, levels = c("some", "no")))

p <- ggplot(accu_exp_hand, aes(x = light_dir, y = mean, fill = handedness))
p + geom_bar(stat = "identity", position = "dodge2", alpha = .9) +
    scale_fill_brewer(type = "qual", palette = "Dark2") +
    scale_y_continuous(labels = scales::label_percent(scale = 1),
                       expand = expansion(mult = c(0, 0.05)),
                       limits = c(0, 100)) +
    geom_text(aes(y = mean, label = round(mean, digits = 1)), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3), family = dviz_font_family) +
    labs(x = NULL, y = "Mean",
         fill = "Handedness",
         title = "Mean accuracy per expertise \nand handedness (NW)") +
    theme_dviz_hgrid() +
    theme(legend.position = "top",
          axis.line.x.bottom = element_line(size = .5, color = "black"),
          axis.ticks.x = element_blank()) + 
    facet_wrap(~ expertise)
```

### Exploring confidence

```{r eda_confidence}
# Confidence per hemisphere (overview)
confi_hem <- df_long_clean %>%
  group_by(hemisphere, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(confidence, pct)

confi_hem <- within(confi_hem, confidence <- factor(confidence, levels = c("high_confidence", "low_confidence", "ambiguous")))

# p <- ggplot(confi_hem, aes(x = hemisphere, y = pct, fill = confidence))
# p + geom_bar(stat = "identity", position = "dodge", alpha = .9) +
#     scale_fill_brewer(type = "qual", palette = "Dark2") +
#     scale_y_continuous(labels = scales::label_percent(scale = 1),
#                        expand = expansion(mult = c(0, 0.05))) +
#     # scale_x_discrete(labels = c("High Confidence", "Low Confidence", "Ambiguous")) +
#     labs(x = NULL, y = "Participants",
#          fill = "Hemisphere",
#          title = "Confidence per hemisphere (%)") +
#     geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3), family = dviz_font_family) +
#     theme_dviz_hgrid() +
#     theme(legend.position = "top",
#           axis.line.x.bottom = element_line(size = .5, colour = "black"),
#           axis.ticks.x = element_blank())

p <- ggplot(confi_hem, aes(x = reorder(hemisphere, -pct), y = pct, fill = confidence))
p + geom_bar(stat = "identity", color = "gray80") +
    scale_fill_viridis_d("Confidence", labels = c("high confidence", "low confidence", "ambiguous")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1),
                       expand = expansion(mult = c(0, 0.05))) +
    scale_x_discrete(labels = c("Southern", "Northern")) +
    labs(x = NULL, y = "Participants",
       fill = "Hemisphere",
       title = "Confidence level per hemisphere") +
    theme(legend.position = "top",
          axis.ticks.y = element_blank()) +
    coord_flip()

# Confidence per gender
confi_gender <- df_long_clean %>%
  group_by(gender, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(gender, confidence, pct)

confi_gender <- within(confi_gender, confidence <- factor(confidence, levels = c("high_confidence", "low_confidence", "ambiguous")))

# p <- ggplot(confi_gender, aes(x = confidence, y = pct, fill = gender))
# p + geom_bar(stat = "identity", position = "dodge2", alpha = .9) +
#     scale_fill_brewer(type = "qual", palette = "Dark2", labels = c("female", "male")) +
#     scale_y_continuous(labels = scales::label_percent(scale = 1),
#                        expand = expansion(mult = c(0, 0.05))) +
#     scale_x_discrete(labels = c("High Confidence", "Low Confidence", "Ambiguous")) +
#     labs(x = NULL, y = "Confidence",
#          fill = "Gender",
#          title = "Confidence per gender (%)") +
#     geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3), family = dviz_font_family) +
#     theme_dviz_hgrid() +
#     theme(legend.position = "top",
#           axis.line.x.bottom = element_line(size = .5, colour = "black"),
#           axis.ticks.x = element_blank())

p <- ggplot(confi_gender, aes(x = gender, y = pct, fill = confidence))
p + geom_bar(stat = "identity", color = "gray80") +
    scale_fill_viridis_d("Confidence", labels = c("high confidence", "low confidence", "ambiguous")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1),
                       expand = expansion(mult = c(0, 0.05))) +
    scale_x_discrete(labels = c("Female", "Male")) +
    labs(x = NULL, y = "Participants",
       fill = "Confidence",
       title = "Confidence level per gender") +
    theme(legend.position = "top",
          axis.ticks.y = element_blank()) +
    coord_flip()

# Confidence per handedness
confi_hand_all <- df_long_clean %>%
  group_by(handedness, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(handedness, confidence, pct)

confi_hand <- df_long_clean %>%
  mutate(hand = ifelse(handedness == "l" | handedness == "b", "l", "r")) %>%
  group_by(hand, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(hand, confidence, pct)

confi_hand <- within(confi_hand, confidence <- factor(confidence, levels = c("high_confidence", "low_confidence", "ambiguous")))
confi_hand <- within(confi_hand, handedness <- factor(hand, levels = c("r", "l")))
confi_hand$hand <- ordered(confi_hand$hand, levels = c("r", "l"))

# p <- ggplot(confi_hand, aes(x = confidence, y = pct, fill = handedness))
# p + geom_bar(stat = "identity", position = "dodge2", alpha = .9) +
#     scale_fill_brewer(type = "qual", palette = "Dark2", labels = c("right-handed", "left-handed", "ambidextrous")) +
#     scale_y_continuous(labels = scales::label_percent(scale = 1),
#                        expand = expansion(mult = c(0, 0.05))) +
#     scale_x_discrete(labels = c("High Confidence", "Low Confidence", "Ambiguous")) +
#     labs(x = NULL, y = "Confidence",
#          fill = "Handedness",
#          title = "Confidence per handedness (%)") +
#     geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3), family = dviz_font_family) +
#     theme_dviz_hgrid() +
#     theme(legend.position = "top",
#           axis.line.x.bottom = element_line(size = .5, colour = "black"),
#           axis.ticks.x = element_blank())

p <- ggplot(confi_hand, aes(x = handedness, y = pct, fill = confidence))
p + geom_bar(stat = "identity", color = "gray80") +
    scale_fill_viridis_d("Confidence", labels = c("high confidence", "low confidence", "ambiguous")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1),
                       expand = expansion(mult = c(0, 0.05))) +
    scale_x_discrete(labels = c("Right-handed", "Left-handed", "Ambidextrous")) +
    labs(x = NULL, y = "Participants",
       fill = "Confidence",
       title = "Confidence level per handedness") +
    theme(legend.position = "top",
          axis.ticks.y = element_blank()) +
    coord_flip()

# Confidence per expertise
confi_exp <- df_long_clean %>%
  group_by(expertise, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(expertise, confidence, pct)

confi_exp <- within(confi_exp, confidence <- factor(confidence, levels = c("high_confidence", "low_confidence", "ambiguous")))
confi_exp <- within(confi_exp, expertise <- factor(expertise, levels = c("some_experience", "no_experience")))

# p <- ggplot(confi_exp, aes(x = confidence, y = pct, fill = expertise))
# p + geom_bar(stat = "identity", position = "dodge2", alpha = .9) +
#     scale_fill_brewer(type = "qual", palette = "Dark2", labels = c("some experience", "no experience")) +
#     scale_y_continuous(labels = scales::label_percent(scale = 1),
#                        expand = expansion(mult = c(0, 0.05))) +
#     scale_x_discrete(labels = c("High Confidence", "Low Confidence", "Ambiguous")) +
#     labs(x = NULL, y = "Confidence",
#          fill = "Expertise",
#          title = "Confidence per expertise (%)") +
#     geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3), family = dviz_font_family) +
#     theme_dviz_hgrid() +
#     theme(legend.position = "top",
#           axis.line.x.bottom = element_line(size = .5, colour = "black"),
#           axis.ticks.x = element_blank())

p <- ggplot(confi_exp, aes(x = expertise, y = pct, fill = confidence))
p + geom_bar(stat = "identity", color = "gray80") +
    scale_fill_viridis_d("Confidence", labels = c("high confidence", "low confidence", "ambiguous")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1),
                       expand = expansion(mult = c(0, 0.05))) +
    scale_x_discrete(labels = c("Some Experience", "No Experience")) +
    labs(x = NULL, y = "Participants",
       fill = "Confidence",
       title = "Confidence level per expertise") +
    theme(legend.position = "top",
          axis.ticks.y = element_blank()) +
    coord_flip()
```
### Accuracy vs confidence per respond

```{r accu_confi}
accu_confi_yes <- df_long_clean %>%
  filter(accuracy == "yes") %>% 
  group_by(light_dir, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(light_dir, confidence, pct)

accu_confi_yes <- within(accu_confi_yes, light_dir <- factor(light_dir, levels = c(0, 337.5, 315, 292.5, 270)))

accu_confi_no <- df_long_clean %>%
  filter(accuracy == "no") %>% 
  group_by(light_dir, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(light_dir, confidence, pct)

accu_confi_no <- within(accu_confi_no, light_dir <- factor(light_dir, levels = c(0, 337.5, 315, 292.5, 270)))

p <- ggplot(accu_confi_yes, aes(x = light_dir, y = pct, fill = confidence))
p + geom_bar(stat = "identity", color = "gray80") +
    scale_fill_viridis_d("Confidence", labels = c("high confidence", "low confidence", "ambiguous")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1),
                       expand = expansion(mult = c(0, 0.05)),
                       limits = c(0, 100)) +
    labs(x = NULL, y = "Participants",
       fill = "Confidence",
       title = "Overall participant's confidence when success (NW)") +
    theme(legend.position = "top",
          axis.ticks.x = element_blank())

p <- ggplot(accu_confi_no, aes(x = light_dir, y = pct, fill = confidence))
p + geom_bar(stat = "identity", color = "gray80") +
    scale_fill_viridis_d("Confidence", labels = c("high confidence", "low confidence", "ambiguous")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1),
                       expand = expansion(mult = c(0, 0.05)),
                       limits = c(0, 100)) +
    labs(x = NULL, y = "Participants",
       fill = "Confidence",
       title = "Overall participant's confidence when failure (NW)") +
    theme(legend.position = "top",
          axis.ticks.x = element_blank())
```

```{r}
# # Plotting correct accuracy vs high confidence
# p1 <- ggplot(accu_confi, aes(x = pct_accu_right, y = pct_high_confi, color = light_dir, label = light_dir))
# p1 <- p1 + geom_point(size = 2.5) +
#     geom_jitter() +
#     geom_smooth(aes(x = pct_accu_right, y = pct_high_confi), method = lm, size = 1.1, color = "gray70", alpha = .2, se = TRUE, fullrange = TRUE) +
#     scale_color_brewer(type = "seq", palette = "Dark2") +
#     scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(40, 100), breaks = seq(40, 100, 10)) +
#     scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(40, 100), breaks = seq(40, 100, 10)) +
#     labs(x = "Mean Accuracy Correct",
#          y = "Mean Confidence High",
#          title = "Correct responses vs high level of confidence per respond",
#          subtitle = "Showing the relation between all the correct responses for accuracy and high confidence per light direction degree",
#          color = "Light Direction Degree") +
#     theme(legend.position = "top")
# 
# # Plotting correct accuracy vs low confidence
# p2 <- ggplot(accu_confi, aes(x = pct_accu_right, y = pct_low_confi, color = light_dir, label = light_dir))
# p2 <- p2 + geom_point(size = 2.5) +
#     geom_jitter() +
#     geom_smooth(aes(x = pct_accu_right, y = pct_low_confi), method = lm, size = 1.1, color = "gray70", alpha = .2, se = TRUE, fullrange = TRUE) +
#     scale_color_brewer(type = "seq", palette = "Dark2") +
#     scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(40, 100), breaks = seq(40, 100, 10)) +
#     scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(10, 40), breaks = seq(10, 40, 10)) +
#     labs(x = "Mean Accuracy Correct",
#          y = "Mean Confidence Low",
#          title = "Correct responses vs low level of confidence per respond",
#          subtitle = "Showing the relation between all the correct responses for accuracy and low confidence per light direction degree",
#          color = "Light Direction Degree") +
#     theme(legend.position = "top")
# 
# # Plotting terrain reversal effect vs high confidence
# p3 <- ggplot(accu_confi, aes(x = pct_accu_wrong, y = pct_high_confi, color = light_dir, label = light_dir))
# p3 <- p3 + geom_point(size = 2.5) +
#     geom_jitter() +
#     geom_smooth(aes(x = pct_accu_wrong, y = pct_high_confi), method = lm, size = 1.1, color = "gray70", alpha = .2, se = TRUE, fullrange = TRUE) +
#     scale_color_brewer(type = "seq", palette = "Dark2") +
#     scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(0, 60), breaks = seq(0, 60, 10)) +
#     scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(50, 100), breaks = seq(50, 100, 10)) +
#     labs(x = "Mean Terrain Reversal Effect",
#          y = "Mean Confidence High",
#          title = "Terrain reversal effect vs high level of confidence per respond",
#          subtitle = "Showing the relation between terrain reversal effect and high confidence per light direction degree",
#          color = "Light Direction Degree") +
#     theme(legend.position = "top")
# 
# # Plotting terrain reversal effect vs low confidence
# p4 <- ggplot(accu_confi, aes(x = pct_accu_wrong, y = pct_low_confi, color = light_dir, label = light_dir))
# p4 <- p4 + geom_point(size = 2.5) +
#     geom_jitter() +
#     geom_smooth(aes(x = pct_accu_wrong, y = pct_low_confi), method = lm, size = 1.1, color = "gray70", alpha = .2, se = TRUE, fullrange = TRUE) +
#     scale_color_brewer(type = "seq", palette = "Dark2") +
#     scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(0, 60), breaks = seq(0, 60, 10)) +
#     scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(0, 60), breaks = seq(0, 60, 10)) +
#     labs(x = "Mean Terrain Reversal Effect",
#          y = "Mean Confidence High",
#          title = "Terrain reversal effect vs low level of confidence per respond",
#          subtitle = "Showing the relation between terrain reversal effect and low confidence per light direction degree",
#          color = "Light Direction Degree") +
#     theme(legend.position = "top")
# 
# # Plotting correct accuracy vs high confidence with 337.5 and 315 light direction degrees highlighted
# color_degrees <- c("#2E74C0", "#CB454A")
# 
# p5 <- ggplot(accu_confi, aes(x = pct_accu_right, y = pct_high_confi, label = light_dir))
# p5 <- p5 + geom_point(size = 2.5, alpha = .07, color = "gray50") +
#     geom_jitter(size = 2.5, alpha = .07, color = "gray50") +
#     geom_point(data = subset(accu_confi, light_dir == "337.5"), aes(x = pct_accu_right, y = pct_high_confi, color = light_dir), size = 2.5) +
#     geom_point(data = subset(accu_confi, light_dir == "315"), aes(x = pct_accu_right, y = pct_high_confi, color = light_dir), size = 2.5) +
#     scale_color_manual(values = color_degrees) +
#     scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(40, 100), breaks = seq(40, 100, 10)) +
#     scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(40, 100), breaks = seq(40, 100, 10)) +
#     geom_text_repel(data = subset(accu_confi, light_dir == "337.5" | light_dir == "315"), aes(x = pct_accu_right, y = pct_high_confi, label = light_dir), size = 2, max.overlaps = 20) +
#     labs(x = "Mean Accuracy Correct",
#          y = "Mean Confidence High",
#          title = "Correct responses vs high level of confidence per respond",
#          subtitle = "Showing the relation between all the correct responses for accuracy and high confidence per light direction degree",
#          color = "Light Direction Degree") +
#     theme(legend.position = "top")
# 
# # Plotting correct accuracy vs low confidence with 337.5 and 315 light direction degrees highlighted
# p6 <- ggplot(accu_confi, aes(x = pct_accu_right, y = pct_low_confi, label = light_dir))
# p6 <- p6 + geom_point(size = 2.5, alpha = .07, color = "gray50") +
#     geom_jitter(size = 2.5, alpha = .07, color = "gray50") +
#     geom_point(data = subset(accu_confi, light_dir == "337.5"), aes(x = pct_accu_right, y = pct_low_confi, color = light_dir), size = 2.5) +
#     geom_point(data = subset(accu_confi, light_dir == "315"), aes(x = pct_accu_right, y = pct_low_confi, color = light_dir), size = 2.5) +
#     scale_color_manual(values = color_degrees) +
#     scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(40, 100), breaks = seq(40, 100, 10)) +
#     scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(10, 40), breaks = seq(10, 40, 10)) +
#     geom_text_repel(data = subset(accu_confi, light_dir == "337.5" | light_dir == "315"), aes(x = pct_accu_right, y = pct_low_confi, label = light_dir), size = 2, max.overlaps = 20) +
#     labs(x = "Mean Accuracy Correct",
#          y = "Mean Confidence Low",
#          title = "Correct responses vs low level of confidence per respond",
#          subtitle = "Showing the relation between all the correct responses for accuracy and low confidence per light direction degree",
#          color = "Light Direction Degree") +
#     theme(legend.position = "top")
# 
# # Plotting terrain reversal effect vs high confidence with 337.5 and 315 light direction degrees highlighted
# p7 <- ggplot(accu_confi, aes(x = pct_accu_wrong, y = pct_high_confi, label = light_dir))
# p7 <- p7 + geom_point(size = 2.5, alpha = .07, color = "gray50") +
#     geom_jitter(size = 2.5, alpha = .07, color = "gray50") +
#     geom_point(data = subset(accu_confi, light_dir == "337.5"), aes(x = pct_accu_wrong, y = pct_high_confi, color = light_dir), size = 2.5) +
#     geom_point(data = subset(accu_confi, light_dir == "315"), aes(x = pct_accu_wrong, y = pct_high_confi, color = light_dir), size = 2.5) +
#     scale_color_manual(values = color_degrees) +
#     scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(0, 60), breaks = seq(0, 60, 10)) +
#     scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(50, 100), breaks = seq(50, 100, 10)) +
#     geom_text_repel(data = subset(accu_confi, light_dir == "337.5" | light_dir == "315"), aes(x = pct_accu_wrong, y = pct_high_confi, label = light_dir), size = 2, max.overlaps = 20) +
#     labs(x = "Mean Terrain Reversal Effect",
#          y = "Mean Confidence High",
#          title = "Terrain reversal effect vs high level of confidence per respond",
#          subtitle = "Showing the relation between terrain reversal effect and high confidence per light direction degree",
#          color = "Light Direction Degree") +
#     theme(legend.position = "top")
# 
# # Plotting terrain reversal effect vs low confidence with 337.5 and 315 light direction degrees highlighted
# p8 <- ggplot(accu_confi, aes(x = pct_accu_wrong, y = pct_low_confi, label = light_dir))
# p8 <- p8 + geom_point(size = 2.5, alpha = .07, color = "gray50") +
#     geom_jitter(size = 2.5, alpha = .07, color = "gray50") +
#     geom_point(data = subset(accu_confi, light_dir == "337.5"), aes(x = pct_accu_wrong, y = pct_low_confi, color = light_dir), size = 2.5) +
#     geom_point(data = subset(accu_confi, light_dir == "315"), aes(x = pct_accu_wrong, y = pct_low_confi, color = light_dir), size = 2.5) +
#     scale_color_manual(values = color_degrees) +
#     scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(0, 60), breaks = seq(0, 60, 10)) +
#     scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(0, 60), breaks = seq(0, 60, 10)) +
#     geom_text_repel(data = subset(accu_confi, light_dir == "337.5" | light_dir == "315"), aes(x = pct_accu_wrong, y = pct_low_confi, label = light_dir), size = 2, max.overlaps = 20) +
#     labs(x = "Mean Terrain Reversal Effect",
#          y = "Mean Confidence Low",
#          title = "Terrain reversal effect vs low level of confidence per respond",
#          subtitle = "Showing the relation between terrain reveral effect and low confidence per light direction degree",
#          color = "Light Direction Degree") +
#     theme(legend.position = "top")
# 
# # Copies of all plots to use them in two grids
# p9 <- p1
# p10 <- p2
# p11 <- p3
# p12 <- p4
# p13 <- p5
# p14 <- p6
# p15 <- p7
# p16 <- p8
# 
# # Removing elements to build the grids
# p9 <- p9 + labs(title = "", subtitle = "") + theme(legend.position = "none")
# p10 <- p10 + labs(title = "", subtitle = "") + theme(legend.position = "none")
# p11 <- p11 + labs(title = "", subtitle = "") + theme(legend.position = "none")
# p12 <- p12 + labs(title = "", subtitle = "") + theme(legend.position = "none")
# p13 <- p13 + labs(title = "", subtitle = "") + theme(legend.position = "none")
# p14 <- p14 + labs(title = "", subtitle = "") + theme(legend.position = "none")
# p15 <- p15 + labs(title = "", subtitle = "") + theme(legend.position = "none")
# p16 <- p16 + labs(title = "", subtitle = "") + theme(legend.position = "none")
# 
# # Showing all plots individually
# p1
# p2
# p3
# p4
# p5
# p6
# p7
# p8
# 
# # Building the first grid
# plot_grid(
#   p9, NULL, p10,
#   NULL, NULL, NULL,
#   p11, NULL, p12,
#   align = 'hv',
#   rel_widths = c(1, .04, 1),
#   rel_heights = c(1, .04, 1)
# )
# 
# # Building the second grid
# plot_grid(
#   p13, NULL, p14,
#   NULL, NULL, NULL,
#   p15, NULL, p16,
#   align = 'hv',
#   rel_widths = c(1, .04, 1),
#   rel_heights = c(1, .04, 1)
# )
```

# Linting

The code in this RMarkdown is linted with the [lintr package](https://github.com/jimhester/lintr), which is based on the [tidyverse style guide](http://style.tidyverse.org/).

```{r echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
# lintr::lint("main.Rmd", linters =
#               lintr::with_defaults(
#                 commented_code_linter = NULL,
#                 trailing_whitespace_linter = NULL
#                 )
#             )
# if you have additional scripts and want them to be linted too, add them here
# lintr::lint("scripts/my_script.R")
```
