---
title: "Perceptual Illusion"
subtitle: "Data Analysis"
author: "Fernando Millan Villalobos"
date: "February 2021"
output:
  html_document:
    code_folding: show
    echo: TRUE
    warning: FALSE
    message: FALSE
    highlight: pygments
    theme: paper
    df_print: kable
    toc: yes
    toc_depth: 4
    number_sections: yes
    toc_float: 
      collapsed: yes
      smooth_scroll: false
  pdf_document:
    toc: yes
  word_document:
    toc: yes
  allways_allow_html: yes
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../", output_file = "index") })
---

```{r, include=FALSE}
## By defult, show code for all chunks in the knitted document,
## as well as the output. To override for a particular chunk
## use echo = FALSE in its options.
knitr::opts_chunk$set(
   echo=TRUE, message=FALSE, warning=FALSE
)
```

```{r, echo=FALSE}
# CONFIG
user_name <- "fernandomillanvillalobos" # your Git username (only needed if
# you want to deploy to GH pages)
project_name <- "2020-perceptual-illusion-master" # adapt!
package_date <- "2021-01-01" # date of the CRAN snapshot that
# the checkpoint package uses
r_version <- "4.0.4" # R-Version to use
options(Ncpus = 4) # use 4 cores for parallelized installation of packages
if (r_version != paste0(version$major, ".", version$minor)) {
  stop("ERROR: specified R version does not match currently used.")
}
```

# Notes

This report was generated on `r Sys.time()`. R version: `r paste0(version$major, ".", version$minor)` on `r version$platform`. For this report, CRAN packages as of `r package_date` were used.

## R-Script & data

The pre-processing and analysis of the data was conducted in the [R project for statistical computing](https://www.r-project.org/). The RMarkdown script used to generate this document can be downloaded [under this link](http:fernandomillanvillalobs.github.io/2020-perceptual-illusion-master/). Through executing `main.Rmd`, the herein described process can be reproduced and this document can be generated. The data and information in the data sets used for this analysis are intended for use only by persons involved in the project, therefore are not available for the general public. The html on-line version of the analysis can be accessed through this [link](https://fernandomillanvillalobos.github.io/2020-perceptual-illusion-master/).

## GitHub

The code for the herein described process can also be freely downloaded from [https://github.com/fernandomillanvillalobs/2020-perceptual-illusion-master](https://github.com/fernandomillanvillalobos/2020-perceptual-illusion-master).

## Data description of output files

Output file: `df_pi.csv` (Example)

| ds_owner  | hemisphere | id | gender | age_group | 
|-----------|------------|----|--------|------------
| j         | northern   | 1  | f      | 30-39     |
| g         | northern   | 2  | m      | 20-29     |
| v         | southern   | 3  | m      | 20-29     |

# Set up

```{r, echo=FALSE}
detach_all_packages <- function() {
  basic_packages_blank <-  c("stats",
                             "graphics",
                             "grDevices",
                             "utils",
                             "datasets",
                             "methods",
                             "base")
  basic_packages <- paste("package:", basic_packages_blank, sep = "")

  package_list <- search()[
    ifelse(unlist(gregexpr("package:", search())) == 1, TRUE, FALSE)]

  package_list <- setdiff(package_list, basic_packages)

  if (length(package_list) > 0)  for (package in package_list) {
    detach(package, character.only = TRUE, unload = TRUE)
    print(paste("package ", package, " detached", sep = ""))
  }
}

detach_all_packages()

# this allows multiple persons to use the same RMarkdown
# without adjusting the working directory by themselves all the time
source("scripts/csf.R")
path_to_wd <- csf() # if this - for some reason - does not work,
# replace with a hardcoded path, like so: "~/projects/rddj-template/analysis/"
if (is.null(path_to_wd) | !dir.exists(path_to_wd)) {
  print("WARNING: No working directory specified for current user")
} else {
  setwd(path_to_wd)
}

# suppress scientific notation
options(scipen = 999)

# suppress summarise info
options(dplyr.summarise.inform = FALSE)

# unload global rstudioapi and knitr again to avoid conflicts with checkpoint
# this is only necessary if executed within RStudio
# outside of RStudio, namely in the knit.sh script, this causes RMarkdown
# rendering to fail, thus should not be executed there
if (Sys.getenv("RSTUDIO") == "1") {
  detach_all_packages()
}
```
## Define packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# from https://mran.revolutionanalytics.com/web/packages/\
# checkpoint/vignettes/using-checkpoint-with-knitr.html
# if you don't need a package, remove it from here (commenting not sufficient)
# tidyverse: see https://blog.rstudio.org/2016/09/15/tidyverse-1-0-0/
cat("
library(rstudioapi)
library(tidyverse, warn.conflicts = FALSE) # ggplot2, dplyr, tidyr, readr, purrr, tibble, magrittr, readxl
library(scales) # scales for ggplot2
library(jsonlite) # json
library(lintr) # code linting
library(sf) # spatial data handling
library(rmarkdown)
library(cowplot) # theme
library(extrafont) # fonts
library(waldo) # compare
library(psych) # some useful funs 
library(ggrepel) # text labels 
library(treemap) # treemap plots 
library(janitor)", # names  
file = "manifest.R")
```

## Install packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# if checkpoint is not yet installed, install it (for people using this
# system for the first time)
if (!require(checkpoint)) {
  if (!require(devtools)) {
    install.packages("devtools", repos = "http://cran.us.r-project.org")
    require(devtools)
  }
  devtools::install_github("RevolutionAnalytics/checkpoint",
                           ref = "v0.4.10", # could be adapted later,
                           # as of now (beginning of July 2017
                           # this is the current release on CRAN)
                           repos = "http://cran.us.r-project.org")
  require(checkpoint)
}
# nolint start
if (!dir.exists("~/.checkpoint")) {
  dir.create("~/.checkpoint")
}
# nolint end
# install packages for the specified CRAN snapshot date
checkpoint(snapshotDate = package_date,
           project = path_to_wd,
           verbose = T,
           scanForPackages = T,
           use.knitr = F,
           R.version = r_version)
rm(package_date)
```

## Load packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
source("manifest.R")
unlink("manifest.R")
sessionInfo()
```
## Load additional scripts

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# if you want to outsource logic to other script files, see README for 
# further information
# Load all visualizations functions as separate scripts
knitr::read_chunk("scripts/dviz.supp.R")
source("scripts/dviz.supp.R")
knitr::read_chunk("scripts/themes.R")
source("scripts/themes.R")
knitr::read_chunk("scripts/plot_grid.R")
source("scripts/plot_grid.R")
knitr::read_chunk("scripts/align_legend.R")
source("scripts/align_legend.R")
knitr::read_chunk("scripts/label_log10.R")
source("scripts/label_log10.R")
```

## Theme

```{r}
theme_set(theme_cowplot(font_size = 11))
```

# Data Wrangling

Importing datasets.

```{r importing}
# Read in data file
df.j <- read.table("input/ignore/j_ds.csv", sep = ",", header = TRUE, check.names = FALSE)
df.g <- read.table("input/ignore/g_ds.csv", sep = ",", header = TRUE, check.names = FALSE)
df.v <- read.table("input/ignore/v_ds.csv", sep = ",", header = TRUE, check.names = FALSE)
df.a <- read.table("input/ignore/a_ds.csv", sep = ",", header = TRUE, check.names = FALSE)

# Cleaning variables names
df.j <- janitor::clean_names(df.j, sep_in = NULL)
df.g <- janitor::clean_names(df.g, sep_in = NULL)
df.v <- janitor::clean_names(df.v, sep_in = NULL)
df.a <- janitor::clean_names(df.a, sep_in = NULL)
```

Cleaning Julien's ds variables.

```{r cleaning_j}
# Values to lowercase
df.j$srm <- unlist(lapply(df.j$srm, tolower))

# Regrouping hours_sleep bottom and top categories
df.j$hours_sleep[df.j$hours_sleep == "<3"] <- "less_than_3"
df.j$hours_sleep[df.j$hours_sleep == ">8"] <- "more_than_8"
df.j$hours_sleep[df.j$hours_sleep == "4"] <- "4-5"
df.j$hours_sleep[df.j$hours_sleep == "5"] <- "5-6"
df.j$hours_sleep[df.j$hours_sleep == "6"] <- "6-7"
df.j$hours_sleep[df.j$hours_sleep == "7"] <- "7-8"
df.j$hours_sleep[df.j$hours_sleep == "8"] <- "7-8"

# Filling empty values for circle_below and circle_above as NAs
df.j$circle_below[df.j$circle_below == ""] <- NA 
df.j$circle_above[df.j$circle_above == ""] <- NA

# Recoding srm, geovis_3d_exposure and satellite_exposure variables
df.j$srm[df.j$srm == "never"] <- 1
df.j$srm[df.j$srm == "rarely"] <- 2
df.j$srm[df.j$srm == "occassionally"] <- 3
df.j$srm[df.j$srm == "often"] <- 4
df.j$srm[df.j$srm == "daily"] <- 5
# srm
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "never"] <- 1
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "rarely"] <- 2
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "occassionally"] <- 3
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "often"] <- 4
df.j$geovis_3d_exposure[df.j$geovis_3d_exposure == "daily"] <- 5
# geovis_3d_exposure
df.j$satellite_exposure[df.j$satellite_exposure == "never"] <- 1
df.j$satellite_exposure[df.j$satellite_exposure == "rarely"] <- 2
df.j$satellite_exposure[df.j$satellite_exposure == "occassionally"] <- 3
df.j$satellite_exposure[df.j$satellite_exposure == "often"] <- 4
df.j$satellite_exposure[df.j$satellite_exposure == "daily"] <- 5
# satellite_exposure

# Adding an expertise var based on srm
df.j$expertise[df.j$srm <= 2] <- "no_experience"
df.j$expertise[df.j$srm >= 2 & df.j$srm <= 4] <- "some_experience"

# Reordering variables
df.j <- df.j %>%
select(1:12, expertise, 13:20, mask, circle_below, circle_above,24:73)
```

Cleaning Gianna's ds variables.

```{r cleaning_g}
# Deleting useless column
df.g$haendigkeit <- NULL

# Renaming variables names
df.g <- df.g %>% 
  rename("age_group" = "alter",
         "education" = "ausbildung",
         "hours_sleep" = "schlaf",
         "color_blindness" = "farbenblindheit",
         "photo_exposure" = "fotos",
         "carto_gis_exposure" = "kartographie",
         "geovis_3d_exposure" = "drei_d_geovis",
         "satellite_exposure" = "satellitenbilder",
         "mask" = "maske")
```

```{r}
# Adding new variables
df.g <- transform(df.g,
                 art_light_r_w = NA, 
                 light_dir_r_s = NA,
                 photo_training = NA,
                 carto_gis_training = NA,
                 geovis_3d_training = NA,
                 satellite_training = NA,
                 expertise = NA,
                 circle_below = NA,
                 circle_above = NA,
                 shapes_01 = NA,
                 shapes_02 = NA,
                 shapes_03 = NA,
                 shapes_04 = NA,
                 shapes_05 = NA,
                 shapes_06 = NA,
                 shapes_07 = NA,
                 shapes_08 = NA,
                 shapes_09 = NA,
                 shapes_10 = NA,
                 srm = NA)

# Recoding education variable
df.g$education[df.g$education == "University: Bachelor degree or equivalent"] <- "bachelor"
df.g$education[df.g$education == "University of applied sciences"] <- "bachelor" # assumption! 
df.g$education[df.g$education == "University: Master degree or equivalent"] <- "master"
df.g$education[df.g$education == "University: Doctoral degree"] <- "doctoral"
df.g$education[df.g$education == "Apprenticeship high school"] <- "high_school"
df.g$education[df.g$education == "Academic high school"] <- "high_school"

# Regrouping age_group category
df.g$age_group[df.g$age_group == "18-29" & df.g$education == "bachelor" | df.g$education == "master"] <- "20-29"
df.g$age_group[df.g$age_group == "18-29" & df.g$education == "high_school"] <- "10-19"

# Regrouping hours_sleep bottom and top categories
df.g$hours_sleep[df.g$hours_sleep == "<3"] <- "less_than_3"
df.g$hours_sleep[df.g$hours_sleep == ">8"] <- "more_than_8"
df.g$hours_sleep[df.g$hours_sleep == "3"] <- "3-4"
df.g$hours_sleep[df.g$hours_sleep == "4"] <- "4-5"
df.g$hours_sleep[df.g$hours_sleep == "5"] <- "5-6"
df.g$hours_sleep[df.g$hours_sleep == "6"] <- "6-7"
df.g$hours_sleep[df.g$hours_sleep == "7"] <- "7-8"
df.g$hours_sleep[df.g$hours_sleep == "8"] <- "7-8"

# Values to lowercase
df.g[, 10:14] <- apply(df.g[, 10:14], 2, tolower)
df.g$color_blindness <- unlist(lapply(df.g$color_blindness, tolower))

# Recoding _exposure variables
df.g$photo_exposure[df.g$photo_exposure == "never"] <- 1
df.g$photo_exposure[df.g$photo_exposure == "rarely"] <- 2
df.g$photo_exposure[df.g$photo_exposure == "occasionally"] <- 3
df.g$photo_exposure[df.g$photo_exposure == "often"] <- 4
df.g$photo_exposure[df.g$photo_exposure == "daily"] <- 5
# photo_exposure
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "never"] <- 1
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "rarely"] <- 2
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "occasionally"] <- 3
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "often"] <- 4
df.g$carto_gis_exposure[df.g$carto_gis_exposure == "daily"] <- 5
# carto_gis_exposure
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "never"] <- 1
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "rarely"] <- 2
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "occasionally"] <- 3
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "often"] <- 4
df.g$geovis_3d_exposure[df.g$geovis_3d_exposure == "daily"] <- 5
# geovis_3d_exposure
df.g$satellite_exposure[df.g$satellite_exposure == "never"] <- 1
df.g$satellite_exposure[df.g$satellite_exposure == "rarely"] <- 2
df.g$satellite_exposure[df.g$satellite_exposure == "occasionally"] <- 3
df.g$satellite_exposure[df.g$satellite_exposure == "often"] <- 4
df.g$satellite_exposure[df.g$satellite_exposure == "daily"] <- 5
# satellite_exposure

# Converting new values to integer
df.g$photo_exposure <- as.integer(df.g$photo_exposure)
df.g$carto_gis_exposure <- as.integer(df.g$carto_gis_exposure)
df.g$geovis_3d_exposure <- as.integer(df.g$geovis_3d_exposure)
df.g$satellite_exposure <- as.integer(df.g$satellite_exposure)

# Adding an expertise var based on maps and/or satellite exposure
df.g$expertise[df.g$carto_gis_exposure <= 3 | df.g$geovis_3d_exposure <= 3 | df.g$satellite_exposure <= 3] <- "no_experience"
df.g$expertise[df.g$carto_gis_exposure > 3 | df.g$geovis_3d_exposure > 3 | df.g$satellite_exposure > 3] <- "some_experience"

# Reordering variables
df.g <- df.g[, names(df.j)]
```

Cleaning Victoria's ds variables.

```{r cleaning_v}
# Adding variables
df.v$hemisphere <- "southern"
df.v$srm <- "NA"
df.v$expertise <- "NA"

# Regrouping age_group category
df.v$age_group[df.v$age_group <= "29"] <- "20-29"

# Splitting character vector from hours_sleep
df.v$hours_sleep <- unlist(strsplit(df.v$hours_sleep, " hours"))

# Recoding education variable
df.v$education <- "bachelor"

# Values to lowercase
df.v$light_dir_r_s <- unlist(lapply(df.v$light_dir_r_s, tolower))

# Filling empty values for exposure variables
df.v$photo_exposure <- ifelse(df.v$photo_exposure == " ", NA, df.v$satellite_exposure)
df.v$carto_gis_exposure <- ifelse(df.v$carto_gis_exposure == " ", NA, df.v$carto_gis_exposure)
df.v$geovis_3d_exposure <- ifelse(df.v$geovis_3d_exposure == " ", NA, df.v$geovis_3d_exposure)
df.v$satellite_exposure <- ifelse(df.v$satellite_exposure == " ", NA, df.v$satellite_exposure)

# Recoding _exposure variables
df.v$photo_exposure[df.v$photo_exposure == "never"] <- 1
df.v$photo_exposure[df.v$photo_exposure == "daily"] <- 5
# photo_exposure
df.v$carto_gis_exposure[df.v$carto_gis_exposure == "never"] <- 1
df.v$carto_gis_exposure[df.v$carto_gis_exposure == "daily"] <- 5
# carto_gis_exposure
df.v$geovis_3d_exposure[df.v$geovis_3d_exposure == "never"] <- 1
df.v$geovis_3d_exposure[df.v$geovis_3d_exposure == "daily"] <- 5
# geovis_3d_exposure
df.v$satellite_exposure[df.v$satellite_exposure == "never"] <- 1
df.v$satellite_exposure[df.v$satellite_exposure == "daily"] <- 5
# satellite_exposure

# Converting new values to integer
df.v$photo_exposure <- as.integer(df.v$photo_exposure)
df.v$carto_gis_exposure <- as.integer(df.v$carto_gis_exposure)
df.v$geovis_3d_exposure <- as.integer(df.v$geovis_3d_exposure)
df.v$satellite_exposure <- as.integer(df.v$satellite_exposure)

# Calculating the expertise mean for every participant
df.v$expertise_mean <- rowSums(df.v[, 14:21], na.rm = TRUE) / 4

# Adding an expertise var based the expertise mean
df.v$expertise[df.v$expertise_mean < 4] <- "no_experience"
df.v$expertise[df.v$expertise_mean >= 4] <- "some_experience"

# Reordering variables
df.v <- df.v[, names(df.j)]
```

Cleaning Amy's ds variables.

```{r cleaning_a}
# Adding hemisphere variable
df.a$hemisphere <- "southern"
df.a$srm <- "NA"
df.a$expertise <- "NA"

# Regrouping age_group category
df.a$age_group[df.a$age_group <= "19"] <- "10-19"
df.a$age_group[df.a$age_group <= "29" & df.a$age_group >= 20] <- "20-29"
df.a$age_group[df.a$age_group <= "39" & df.a$age_group >= 30] <- "30-39"
df.a$age_group[df.a$age_group <= "49" & df.a$age_group >= 40] <- "40-49"
df.a$age_group[df.a$age_group <= "59" & df.a$age_group >= 50] <- "50-59"
df.a$age_group[df.a$age_group <= "69" & df.a$age_group >= 60] <- "60-69"

# Recoding education variable
df.a$education[df.a$education == "Currently registered at University/College for Bachelor degree or equivalent"] <- "bachelor"
df.a$education[df.a$education == "University/College: Bachelor degree or equivalent"] <- "bachelor"
df.a$education[df.a$education == "University/College: Honours, Masters, PhD degree or equivalent"] <- "master"
df.a$education[df.a$education == "High school diploma or equivalent ( e.g. NCS or matric )"] <- "high_school"

# Recoding hours_sleep
df.a$hours_sleep <- unlist(strsplit(df.a$hours_sleep, " hours")) # splitting characters
df.a$hours_sleep <- unlist(lapply(df.a$hours_sleep, tolower)) # values to lowercase  
df.a$hours_sleep[df.a$hours_sleep == "more than 8"] <- "more_than_8" # recoding

# Values to lowercase
df.a$art_light_r_w <- unlist(lapply(df.a$art_light_r_w, tolower))
df.a$light_dir_r_s <- unlist(lapply(df.a$light_dir_r_s, tolower))
df.a$color_blindness <- unlist(lapply(df.a$color_blindness, tolower))

# Filling empty values for exposure variables
df.a$photo_exposure <- ifelse(df.a$photo_exposure == " ", NA, df.a$satellite_exposure)
df.a$carto_gis_exposure <- ifelse(df.a$carto_gis_exposure == " ", NA, df.a$carto_gis_exposure)
df.a$geovis_3d_exposure <- ifelse(df.a$geovis_3d_exposure == " ", NA, df.a$geovis_3d_exposure)
df.a$satellite_exposure <- ifelse(df.a$satellite_exposure == " ", NA, df.a$satellite_exposure)

# Recoding _exposure variables
df.a$photo_exposure[df.a$photo_exposure == "never"] <- 1
df.a$photo_exposure[df.a$photo_exposure == "daily"] <- 5
# photo_exposure
df.a$carto_gis_exposure[df.a$carto_gis_exposure == "never"] <- 1
df.a$carto_gis_exposure[df.a$carto_gis_exposure == "daily"] <- 5
# carto_gis_exposure
df.a$geovis_3d_exposure[df.a$geovis_3d_exposure == "never"] <- 1
df.a$geovis_3d_exposure[df.a$geovis_3d_exposure == "daily"] <- 5
# geovis_3d_exposure
df.a$satellite_exposure[df.a$satellite_exposure == "never"] <- 1
df.a$satellite_exposure[df.a$satellite_exposure == "daily"] <- 5
# satellite_exposure

# Converting new values to integer
df.a$photo_exposure <- as.integer(df.a$photo_exposure)
df.a$carto_gis_exposure <- as.integer(df.a$carto_gis_exposure)
df.a$geovis_3d_exposure <- as.integer(df.a$geovis_3d_exposure)
df.a$satellite_exposure <- as.integer(df.a$satellite_exposure)

# Calculating the expertise mean for every participant
df.a$expertise_mean <- rowSums(df.a[, 14:21], na.rm = TRUE) / 4

# Adding an expertise var based on the expertise mean
df.a$expertise[df.a$expertise_mean < 4] <- "no_experience"
df.a$expertise[df.a$expertise_mean >= 4] <- "some_experience"

# Reordering variables
df.a <- df.a[, names(df.j)]
```

Creating all-in-one df for analysis and viz.

```{r wide_to_long}
# Creating a all-in-one wide df
df_wide <- rbind(df.j, df.g, df.v, df.a)

# Converting numeric vars to factor
cols <- c(35:74)
df_wide[, cols] <- lapply(df_wide[, cols] , factor)

# Reshaping from wide to long
df_long <- df_wide %>% pivot_longer(
  cols = q10_r000_0:q80_v135_337.5,
  names_to = c("landform", "land_dir", "light_dir"),
  names_pattern = "q?_(.)(.*)_(.*?..*)",
  values_to = "respond")
```

# Data Analysis

## Setting accuracy and confidence.

```{r accuracy_confidence}
# Setting accuracy
ridge_t <- df_long$landform == "r" & (df_long$respond == "4" | df_long$respond == "5")
valley_t <- df_long$landform == "v" & (df_long$respond == "1" | df_long$respond == "2")
df_long$accuracy <- ifelse(ridge_t | valley_t , "yes", "no")

# Setting accuracy score
df_long$accuracy_score <- ifelse(df_long$respond == "1" | df_long$respond == "5", 1, 0)

# Setting confidence (out of 40)
df_long$confidence <- "NA"
df_long$confidence[df_long$respond == "1" | df_long$respond == "5"] <- "high_confidence"
df_long$confidence[df_long$respond == "2" | df_long$respond == "4"] <- "low_confidence"
df_long$confidence[df_long$respond == "3"] <- "ambiguous"

# Setting confidence score (out of 80)
df_long$confidence_score[df_long$respond == "1" | df_long$respond == "5"] <- 2
df_long$confidence_score[df_long$respond == "2" | df_long$respond == "4"] <- 1
df_long$confidence_score[df_long$respond == "3"] <- 0
```

## EDA

### Exploring accuracy

```{r eda_accuracy}
# Accuracy per hemisphere
accu_hem <- df_long %>%
  group_by(hemisphere, accuracy) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(accuracy, hemisphere, pct)

p <- ggplot(accu_hem, aes(x = reorder(accuracy, -pct), y = pct, fill = hemisphere, label = pct))
p + geom_bar(stat = "identity", position = "dodge2") +
    scale_fill_brewer(type = "qual", palette = "Dark2") +
    scale_y_continuous(labels = scales::label_percent(scale = 1)) +
    scale_x_discrete(labels = c("Correct", "Inverse")) +
    labs(x = NULL, y = "Mean Accuracy", 
         fill = "Hemisphere", 
         title = "Mean accuracy per hemisphere (%)") +
    geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3)) +
    theme(legend.position = "top")

# Accuracy per hemisphere and light direction
accu_hem_degrees <- df_long %>%
  group_by(hemisphere, accuracy, light_dir) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(accuracy, light_dir, pct)

accu_hem_degrees <- within(accu_hem_degrees, light_dir <- factor(light_dir, levels = c("0", "337.5", "315", "292.5", "270")))
accu_hem_degrees <- within(accu_hem_degrees, accuracy <- factor(accuracy, levels = c("yes", "no")))
accu_hem_degrees$light_dir <- ordered(accu_hem_degrees$light_dir, levels = c("0", "337.5", "315", "292.5", "270")) # Converting degrees to ordered factors

p <- ggplot(accu_hem_degrees, aes(x = light_dir, y = pct, fill = hemisphere, label = pct))
p + geom_bar(stat = "identity", position = "dodge2") +
  scale_fill_brewer(type = "qual", palette = "Dark2") +
  labs(x = "Light Direction (degrees)", y = "Mean Accuracy", 
     fill = "Hemisphere", 
     title = "Mean accuracy per hemisphere and light direction (%)") +
  scale_y_continuous(labels = scales::label_percent(scale = 1)) +
  geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), hjust = -0.20, size = rel(3)) +
  facet_grid(~ accuracy, labeller = labeller(accuracy = c(`no` = "Inverse", `yes` = "Correct"))) +
  coord_flip() +
  theme(legend.position = "bottom")

accu_hem_degrees_inverse <- df_long %>%
  group_by(hemisphere, accuracy, light_dir) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  filter(accuracy == "no") %>% 
  select(accuracy, light_dir, pct)

accu_hem_degrees_inverse %>% 
  treemap::treemap(
        index = c("hemisphere", "light_dir"),
        vSize = "pct",
        title = "Terrain inversal effect per hemisphere and light direction",
        fontsize.title = 12
        )

# Accuracy per gender
accu_gender <- df_long %>%
  group_by(gender, accuracy) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(gender, accuracy,pct)

accu_gender <- within(accu_gender, accuracy <- factor(accuracy, levels = c("yes", "no")))  

p <- ggplot(accu_gender, aes(x = accuracy, y = pct, fill = gender, label = pct))
p + geom_bar(stat = "identity", position = "dodge2") +
    scale_fill_brewer(type = "qual", palette = "Dark2", labels = c("female", "male")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1)) +
    scale_x_discrete(labels = c("Correct", "Inverse")) +
    labs(x = NULL, y = "Mean Accuracy",
         fill = "Gender",
         title = "Mean accuracy per gender (%)") +
    geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3)) +
    theme(legend.position = "top")

# Accuracy per handedness
accu_hand <- df_long %>%
  group_by(handedness, accuracy) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(handedness, accuracy,pct)

accu_hand <- within(accu_hand, accuracy <- factor(accuracy, levels = c("yes", "no")))
accu_hand <- within(accu_hand, handedness <- factor(handedness, levels = c("b", "r", "l")))
accu_hand$handedness <- ordered(accu_hand$handedness, levels = c("r", "l", "b"))

p <- ggplot(accu_hand, aes(x = accuracy, y = pct, fill = handedness, label = pct))
p + geom_bar(stat = "identity", position = "dodge2") +
    scale_fill_brewer(type = "qual", palette = "Dark2", labels = c("right-handed", "left-handed", "ambidextrous")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1)) +
    scale_x_discrete(labels = c("Correct", "Inverse")) +
    labs(x = NULL, y = "Mean Accuracy",
         fill = "Handedness",
         title = "Mean accuracy per handedness (%)") +
    geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3)) +
    theme(legend.position = "top")

# Accuracy per expertise
accu_exp <- df_long %>%
  group_by(expertise, accuracy) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(expertise, accuracy,pct)

accu_exp <- within(accu_exp, accuracy <- factor(accuracy, levels = c("yes", "no")))
accu_exp <- within(accu_exp, expertise <- factor(expertise, levels = c("some_experience", "no_experience")))
  
p <- ggplot(accu_exp, aes(x = accuracy, y = pct, fill = expertise, label = pct))
p + geom_bar(stat = "identity", position = "dodge2") +
    scale_fill_brewer(type = "qual", palette = "Dark2", labels = c("some experience", "no experience")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1)) +
    scale_x_discrete(labels = c("Correct", "Inverse")) +
    labs(x = NULL, y = "Mean Accuracy",
         fill = "Expertise",
         title = "Mean accuracy per expertise (%)") +
    geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3)) +
    theme(legend.position = "top")
```
### Exploring confidence

```{r eda_confidence}
# Confidence per hemisphere
confi_hem <- df_long %>%
  group_by(hemisphere, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(confidence, pct)

confi_hem <- within(confi_hem, confidence <- factor(confidence, levels = c("high_confidence", "low_confidence", "ambiguous")))

p <- ggplot(confi_hem, aes(x = confidence, y = pct, fill = hemisphere))
p + geom_bar(stat = "identity", position = "dodge2") +
    scale_fill_brewer(type = "qual", palette = "Dark2") +
    scale_y_continuous(labels = scales::label_percent(scale = 1)) +
    scale_x_discrete(labels = c("High Confidence", "Low Confidence", "Ambiguous")) +
    labs(x = NULL, y = "Mean Confidence",
         fill = "Hemisphere",
         title = "Mean confidence per hemisphere (%)") +
    geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3)) +
    theme(legend.position = "top")

p <- ggplot(confi_hem, aes(x = reorder(hemisphere, -pct), y = pct, fill = confidence))
p + geom_bar(stat = "identity", color = "gray80") +
    scale_fill_viridis_d("Confidence", labels = c("high confidence", "low confidence", "ambiguous")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1)) +
    scale_x_discrete(labels = c("Southern", "Northern")) +
    labs(x = NULL, y = "Mean Confidence",
       fill = "Hemisphere",
       title = "Mean confidence per hemisphere (%)") +
    theme(legend.position = "top") +
    coord_flip()

# Confidence per gender
confi_gender <- df_long %>%
  group_by(gender, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(gender, confidence, pct)

confi_gender <- within(confi_gender, confidence <- factor(confidence, levels = c("high_confidence", "low_confidence", "ambiguous")))

p <- ggplot(confi_gender, aes(x = confidence, y = pct, fill = gender))
p + geom_bar(stat = "identity", position = "dodge2") +
    scale_fill_brewer(type = "qual", palette = "Dark2", labels = c("female", "male")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1)) +
    scale_x_discrete(labels = c("High Confidence", "Low Confidence", "Ambiguous")) +
    labs(x = NULL, y = "Mean Confidence",
         fill = "Gender",
         title = "Mean confidence per gender (%)") +
    geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3)) +
    theme(legend.position = "top")

p <- ggplot(confi_gender, aes(x = gender, y = pct, fill = confidence))
p + geom_bar(stat = "identity", color = "gray80") +
    scale_fill_viridis_d("Confidence", labels = c("high confidence", "low confidence", "ambiguous")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1)) +
    scale_x_discrete(labels = c("Female", "Male")) +
    labs(x = NULL, y = "Mean Confidence",
       fill = "Confidence",
       title = "Mean confidence per gender (%)") +
    theme(legend.position = "top") +
    coord_flip()

# Confidence per handedness
confi_hand <- df_long %>%
  group_by(handedness, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(handedness, confidence, pct)

confi_hand <- within(confi_hand, confidence <- factor(confidence, levels = c("high_confidence", "low_confidence", "ambiguous")))
confi_hand <- within(confi_hand, handedness <- factor(handedness, levels = c("b", "r", "l")))
confi_hand$handedness <- ordered(confi_hand$handedness, levels = c("r", "l", "b"))

p <- ggplot(confi_hand, aes(x = confidence, y = pct, fill = handedness))
p + geom_bar(stat = "identity", position = "dodge2") +
    scale_fill_brewer(type = "qual", palette = "Dark2", labels = c("right-handed", "left-handed", "ambidextrous")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1)) +
    scale_x_discrete(labels = c("High Confidence", "Low Confidence", "Ambiguous")) +
    labs(x = NULL, y = "Mean Confidence",
         fill = "Handedness",
         title = "Mean confidence per handedness (%)") +
    geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3)) +
    theme(legend.position = "top")

p <- ggplot(confi_hand, aes(x = handedness, y = pct, fill = confidence))
p + geom_bar(stat = "identity", color = "gray80") +
    scale_fill_viridis_d("Confidence", labels = c("high confidence", "low confidence", "ambiguous")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1)) +
    scale_x_discrete(labels = c("Right-handed", "Left-handed", "Ambidextrous")) +
    labs(x = NULL, y = "Mean Confidence",
       fill = "Confidence",
       title = "Mean confidence per handedness (%)") +
    theme(legend.position = "top") +
    coord_flip()

# Confidence per expertise
confi_exp <- df_long %>%
  group_by(expertise, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct = round(N / sum(N) * 100, 1)) %>%
  select(expertise, confidence, pct)

confi_exp <- within(confi_exp, confidence <- factor(confidence, levels = c("high_confidence", "low_confidence", "ambiguous")))
confi_exp <- within(confi_exp, expertise <- factor(expertise, levels = c("some_experience", "no_experience")))

p <- ggplot(confi_exp, aes(x = confidence, y = pct, fill = expertise))
p + geom_bar(stat = "identity", position = "dodge2") +
    scale_fill_brewer(type = "qual", palette = "Dark2", labels = c("some experience", "no experience")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1)) +
    scale_x_discrete(labels = c("High Confidence", "Low Confidence", "Ambiguous")) +
    labs(x = NULL, y = "Mean Confidence",
         fill = "Expertise",
         title = "Mean confidence per expertise (%)") +
    geom_text(aes(y = pct, label = pct), position = position_dodge2(width = 1), vjust = -0.40, size = rel(3)) +
    theme(legend.position = "top")

p <- ggplot(confi_exp, aes(x = expertise, y = pct, fill = confidence))
p + geom_bar(stat = "identity", color = "gray80") +
    scale_fill_viridis_d("Confidence", labels = c("high confidence", "low confidence", "ambiguous")) +
    scale_y_continuous(labels = scales::label_percent(scale = 1)) +
    scale_x_discrete(labels = c("Some Experience", "No Experience")) +
    labs(x = NULL, y = "Mean Confidence",
       fill = "Confidence",
       title = "Mean confidence per expertise (%)") +
    theme(legend.position = "top") +
    coord_flip()
```

### Confidence vs accuracy per respond.

```{r}
#  Setting accuracy per respond
accu_right_resp_degrees <- df_long %>%
  group_by(land_dir, light_dir, accuracy) %>% 
  summarize(N = n()) %>% 
  mutate(pct_accu_right = round(N / sum(N) * 100, 1)) %>% 
  filter(accuracy == "yes") %>% 
  select(-c(accuracy, N))

accu_wrong_resp_degrees <- df_long %>%
  group_by(land_dir, light_dir, accuracy) %>%
  summarize(N = n()) %>%
  mutate(pct_accu_wrong = round(N / sum(N) * 100, 1)) %>%
  filter(accuracy == "no") %>%
  select(-c(accuracy, N))

accu <- left_join(accu_right_resp_degrees, accu_wrong_resp_degrees, by = c("land_dir", "light_dir"))

#  Setting confidence per respond
confi_high_resp_degrees <- df_long %>%
  group_by(land_dir, light_dir, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct_high_confi = round(N / sum(N) * 100, 1)) %>%
  filter(confidence == "high_confidence") %>%
  select(-c(confidence, N))

confi_low_resp_degrees <- df_long %>%
  group_by(land_dir, light_dir, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct_low_confi = round(N / sum(N) * 100, 1)) %>%
  filter(confidence == "low_confidence") %>%
  select(-c(confidence, N))

confi_amb_resp_degrees <- df_long %>%
  group_by(land_dir, light_dir, confidence) %>%
  summarize(N = n()) %>%
  mutate(pct_amb_confi = round(N / sum(N) * 100, 1)) %>%
  filter(confidence == "ambiguous") %>%
  select(-c(confidence, N))

confi1 <- left_join(confi_high_resp_degrees, confi_low_resp_degrees, by = c("land_dir", "light_dir"))
confi2 <- left_join(confi1, confi_amb_resp_degrees, by = c("land_dir", "light_dir"))
accu_confi <- left_join(accu, confi2, by = c("land_dir", "light_dir"))

# Plotting correct accuracy vs high confidence
p1 <- ggplot(accu_confi, aes(x = pct_accu_right, y = pct_high_confi, color = light_dir, label = light_dir))
p1 <- p1 + geom_point(size = 2.5) +
    geom_jitter() +
    geom_smooth(aes(x = pct_accu_right, y = pct_high_confi), method = lm, size = 1.1, color = "gray70", alpha = .2, se = TRUE, fullrange = TRUE) +
    scale_color_brewer(type = "seq", palette = "Dark2") +
    scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(40, 100), breaks = seq(40, 100, 10)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(40, 100), breaks = seq(40, 100, 10)) +
    labs(x = "Mean Accuracy Correct",
         y = "Mean Confidence High",
         title = "Correct responses vs high level of confidence per respond",
         subtitle = "Showing the relation between all the correct responses for accuracy and high confidence per light direction degree",
         color = "Light Direction Degree") +
    theme(legend.position = "top")

# Plotting correct accuracy vs low confidence
p2 <- ggplot(accu_confi, aes(x = pct_accu_right, y = pct_low_confi, color = light_dir, label = light_dir))
p2 <- p2 + geom_point(size = 2.5) +
    geom_jitter() +
    geom_smooth(aes(x = pct_accu_right, y = pct_low_confi), method = lm, size = 1.1, color = "gray70", alpha = .2, se = TRUE, fullrange = TRUE) +
    scale_color_brewer(type = "seq", palette = "Dark2") +
    scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(40, 100), breaks = seq(40, 100, 10)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(10, 40), breaks = seq(10, 40, 10)) +
    labs(x = "Mean Accuracy Correct",
         y = "Mean Confidence Low",
         title = "Correct responses vs low level of confidence per respond",
         subtitle = "Showing the relation between all the correct responses for accuracy and low confidence per light direction degree",
         color = "Light Direction Degree") +
    theme(legend.position = "top")

# Plotting terrain reversal effect vs high confidence
p3 <- ggplot(accu_confi, aes(x = pct_accu_wrong, y = pct_high_confi, color = light_dir, label = light_dir))
p3 <- p3 + geom_point(size = 2.5) +
    geom_jitter() +
    geom_smooth(aes(x = pct_accu_wrong, y = pct_high_confi), method = lm, size = 1.1, color = "gray70", alpha = .2, se = TRUE, fullrange = TRUE) +
    scale_color_brewer(type = "seq", palette = "Dark2") +
    scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(0, 60), breaks = seq(0, 60, 10)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(50, 100), breaks = seq(50, 100, 10)) +
    labs(x = "Mean Terrain Reversal Effect",
         y = "Mean Confidence High",
         title = "Terrain reversal effect vs high level of confidence per respond",
         subtitle = "Showing the relation between terrain reversal effect and high confidence per light direction degree",
         color = "Light Direction Degree") +
    theme(legend.position = "top")

# Plotting terrain reversal effect vs low confidence
p4 <- ggplot(accu_confi, aes(x = pct_accu_wrong, y = pct_low_confi, color = light_dir, label = light_dir))
p4 <- p4 + geom_point(size = 2.5) +
    geom_jitter() +
    geom_smooth(aes(x = pct_accu_wrong, y = pct_low_confi), method = lm, size = 1.1, color = "gray70", alpha = .2, se = TRUE, fullrange = TRUE) +
    scale_color_brewer(type = "seq", palette = "Dark2") +
    scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(0, 60), breaks = seq(0, 60, 10)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(0, 60), breaks = seq(0, 60, 10)) +
    labs(x = "Mean Terrain Reversal Effect",
         y = "Mean Confidence High",
         title = "Terrain reversal effect vs low level of confidence per respond",
         subtitle = "Showing the relation between terrain reversal effect and low confidence per light direction degree",
         color = "Light Direction Degree") +
    theme(legend.position = "top")

# Plotting correct accuracy vs high confidence with 337.5 and 315 light direction degrees highlighted
color_degrees <- c("#2E74C0", "#CB454A")

p5 <- ggplot(accu_confi, aes(x = pct_accu_right, y = pct_high_confi, label = light_dir))
p5 <- p5 + geom_point(size = 2.5, alpha = .07, color = "gray50") +
    geom_jitter(size = 2.5, alpha = .07, color = "gray50") +
    geom_point(data = subset(accu_confi, light_dir == "337.5"), aes(x = pct_accu_right, y = pct_high_confi, color = light_dir), size = 2.5) +
    geom_point(data = subset(accu_confi, light_dir == "315"), aes(x = pct_accu_right, y = pct_high_confi, color = light_dir), size = 2.5) +
    scale_color_manual(values = color_degrees) +
    scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(40, 100), breaks = seq(40, 100, 10)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(40, 100), breaks = seq(40, 100, 10)) +
    geom_text_repel(data = subset(accu_confi, light_dir == "337.5" | light_dir == "315"), aes(x = pct_accu_right, y = pct_high_confi, label = light_dir), size = 2, max.overlaps = 20) +
    labs(x = "Mean Accuracy Correct",
         y = "Mean Confidence High",
         title = "Correct responses vs high level of confidence per respond",
         subtitle = "Showing the relation between all the correct responses for accuracy and high confidence per light direction degree",
         color = "Light Direction Degree") +
    theme(legend.position = "top")

# Plotting correct accuracy vs low confidence with 337.5 and 315 light direction degrees highlighted
p6 <- ggplot(accu_confi, aes(x = pct_accu_right, y = pct_low_confi, label = light_dir))
p6 <- p6 + geom_point(size = 2.5, alpha = .07, color = "gray50") +
    geom_jitter(size = 2.5, alpha = .07, color = "gray50") +
    geom_point(data = subset(accu_confi, light_dir == "337.5"), aes(x = pct_accu_right, y = pct_low_confi, color = light_dir), size = 2.5) +
    geom_point(data = subset(accu_confi, light_dir == "315"), aes(x = pct_accu_right, y = pct_low_confi, color = light_dir), size = 2.5) +
    scale_color_manual(values = color_degrees) +
    scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(40, 100), breaks = seq(40, 100, 10)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(10, 40), breaks = seq(10, 40, 10)) +
    geom_text_repel(data = subset(accu_confi, light_dir == "337.5" | light_dir == "315"), aes(x = pct_accu_right, y = pct_low_confi, label = light_dir), size = 2, max.overlaps = 20) +
    labs(x = "Mean Accuracy Correct",
         y = "Mean Confidence Low",
         title = "Correct responses vs low level of confidence per respond",
         subtitle = "Showing the relation between all the correct responses for accuracy and low confidence per light direction degree",
         color = "Light Direction Degree") +
    theme(legend.position = "top")

# Plotting terrain reversal effect vs high confidence with 337.5 and 315 light direction degrees highlighted
p7 <- ggplot(accu_confi, aes(x = pct_accu_wrong, y = pct_high_confi, label = light_dir))
p7 <- p7 + geom_point(size = 2.5, alpha = .07, color = "gray50") +
    geom_jitter(size = 2.5, alpha = .07, color = "gray50") +
    geom_point(data = subset(accu_confi, light_dir == "337.5"), aes(x = pct_accu_wrong, y = pct_high_confi, color = light_dir), size = 2.5) +
    geom_point(data = subset(accu_confi, light_dir == "315"), aes(x = pct_accu_wrong, y = pct_high_confi, color = light_dir), size = 2.5) +
    scale_color_manual(values = color_degrees) +
    scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(0, 60), breaks = seq(0, 60, 10)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(50, 100), breaks = seq(50, 100, 10)) +
    geom_text_repel(data = subset(accu_confi, light_dir == "337.5" | light_dir == "315"), aes(x = pct_accu_wrong, y = pct_high_confi, label = light_dir), size = 2, max.overlaps = 20) +
    labs(x = "Mean Terrain Reversal Effect",
         y = "Mean Confidence High",
         title = "Terrain reversal effect vs high level of confidence per respond",
         subtitle = "Showing the relation between terrain reversal effect and high confidence per light direction degree",
         color = "Light Direction Degree") +
    theme(legend.position = "top")

# Plotting terrain reversal effect vs low confidence with 337.5 and 315 light direction degrees highlighted
p8 <- ggplot(accu_confi, aes(x = pct_accu_wrong, y = pct_low_confi, label = light_dir))
p8 <- p8 + geom_point(size = 2.5, alpha = .07, color = "gray50") +
    geom_jitter(size = 2.5, alpha = .07, color = "gray50") +
    geom_point(data = subset(accu_confi, light_dir == "337.5"), aes(x = pct_accu_wrong, y = pct_low_confi, color = light_dir), size = 2.5) +
    geom_point(data = subset(accu_confi, light_dir == "315"), aes(x = pct_accu_wrong, y = pct_low_confi, color = light_dir), size = 2.5) +
    scale_color_manual(values = color_degrees) +
    scale_x_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(0, 60), breaks = seq(0, 60, 10)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = TRUE, scale = 1), limits = c(0, 60), breaks = seq(0, 60, 10)) +
    geom_text_repel(data = subset(accu_confi, light_dir == "337.5" | light_dir == "315"), aes(x = pct_accu_wrong, y = pct_low_confi, label = light_dir), size = 2, max.overlaps = 20) +
    labs(x = "Mean Terrain Reversal Effect",
         y = "Mean Confidence Low",
         title = "Terrain reversal effect vs low level of confidence per respond",
         subtitle = "Showing the relation between terrain reveral effect and low confidence per light direction degree",
         color = "Light Direction Degree") +
    theme(legend.position = "top")

# Copies of all plots to use them in two grids
p9 <- p1
p10 <- p2
p11 <- p3
p12 <- p4
p13 <- p5
p14 <- p6
p15 <- p7
p16 <- p8

# Removing elements to build the grids
p9 <- p9 + labs(title = "", subtitle = "") + theme(legend.position = "none")
p10 <- p10 + labs(title = "", subtitle = "") + theme(legend.position = "none")
p11 <- p11 + labs(title = "", subtitle = "") + theme(legend.position = "none")
p12 <- p12 + labs(title = "", subtitle = "") + theme(legend.position = "none")
p13 <- p13 + labs(title = "", subtitle = "") + theme(legend.position = "none")
p14 <- p14 + labs(title = "", subtitle = "") + theme(legend.position = "none")
p15 <- p15 + labs(title = "", subtitle = "") + theme(legend.position = "none")
p16 <- p16 + labs(title = "", subtitle = "") + theme(legend.position = "none")

# Showing all plots individually
p1
p2
p3
p4
p5
p6
p7
p8

# Building the first grid
plot_grid(
  p9, NULL, p10,
  NULL, NULL, NULL,
  p11, NULL, p12,
  align = 'hv',
  rel_widths = c(1, .04, 1),
  rel_heights = c(1, .04, 1)
)

# Building the second grid
plot_grid(
  p13, NULL, p14,
  NULL, NULL, NULL,
  p15, NULL, p16,
  align = 'hv',
  rel_widths = c(1, .04, 1),
  rel_heights = c(1, .04, 1)
)
```

# Linting

The code in this RMarkdown is linted with the [lintr package](https://github.com/jimhester/lintr), which is based on the [tidyverse style guide](http://style.tidyverse.org/).

```{r echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
lintr::lint("main.Rmd", linters =
              lintr::with_defaults(
                commented_code_linter = NULL,
                trailing_whitespace_linter = NULL
                )
            )
# if you have additional scripts and want them to be linted too, add them here
# lintr::lint("scripts/my_script.R")
```
